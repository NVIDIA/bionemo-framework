---
default:
  image: docker:20.10.16


stages:
  - code_format
  - build
  - test
  - jet
  - deploy

variables:
  # docker build options
  DOCKER_HOST: tcp://docker:2376
  DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
  DOCKER_TLS_VERIFY: 1
  DOCKER_TLS_CERTDIR: "/certs"
  DOCKER_BUILDKIT: 1
  BUILDKIT_PROGRESS: plain
  # image repositories
  NGC_REPO_NAME: "nvcr.io/nvidian/cvai_bnmo_trng/bionemo"
  GITLAB_REPO_NAME: "$CI_REGISTRY_IMAGE"
  IMAGE_REPO_NAME:
    value: "$CI_REGISTRY_IMAGE"
    options:
      - "$CI_REGISTRY_IMAGE"
      - "$NGC_REPO_NAME"
    description: "Allows to control whether NGC or Gitlab registry is used."
  # image tags, or used therein
  PIPELINE_TAG: "pipeline-${CI_PIPELINE_ID}"
  IMAGE_TAG: "${CI_COMMIT_SHA}"
  SUFFIX_DEV: "-devel"
  SUFFIX_DOCS: "-docs"
  SUFFIX_QA: "-qa"
  DATE: "${CI_PIPELINE_CREATED_AT}"
  # fully-qualified image names
  IMAGE_NAME: "${IMAGE_REPO_NAME}:${IMAGE_TAG}"
  NEMO_NIGHTLY_IMAGE: "nvcr.io/nvidian/nemo-nightly:latest-nightly-main"
  NGC_CLI_FORMAT_TYPE: ascii
  NGC_CLI_ORG: nvidian
  # TODO(dorotat): change to cvai_bnmo_trng when we move data and checkpoints
  NGC_CLI_TEAM: clara-lifesciences
  # JET variables
  JET_WORKLOAD_FOLDER: "training-inference-unit-tests"
  JET_WORKLOADS_DIR: "internal/jet/workloads/$JET_WORKLOAD_FOLDER"
  ### variables excluding stages of the CI pipeline
  EXCLUDE_DOCKER_IMAGE_BUILD: "false"
  EXCLUDE_DOCS_BUILD: "false"
  EXCLUDE_PYTEST: "false"
  EXCLUDE_JET: "false"
  EXCLUDE_DEPLOY: "true"
  ### variables allowed to be modified when creating pipelines in web Gitlab GUI via Build -> Pipelines -> Run pipeline button
  ### ie when $CI_PIPELINE_SOURCE == "web"
  PYTEST:
    value: "true"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to run pytest stages. Set to 'true' by default."
  JET:
    value: "true"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to run tests in JET. Set to 'true' by default."
  NIGHTLY:
    value: "false"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to use nightly NeMo docker image as base. Set to 'false' by default."
  JET_CONV_TEST:
    value: "false"
    options:
      - "false"
      - "true"
    description: "A flag that determines whether to run partial convergence tests in CI. Set to 'false' by default."
  QA_DOCKER_DEPLOY:
    value: "false"
    options:
      - "false"
      - "true"
    description: "a flag that determines whether to built & push a docker image for QA. Set to 'false' by default. Remark that only the docker image build and deploy is executed during this pipeline 
    resulting in images being pushed to both GitLab and NGC repositories, each tagged with the suffix '${CI_COMMIT_BRANCH}--${DATE_YMD}--${CI_COMMIT_SHA}-qa'"

# TODO(dorotat) solution with SKIP_CI flag is error-prone and should be replaced with better logic!!!!
workflow:
  rules:
    - if: $CI_COMMIT_BRANCH != "dev" && $QA_DOCKER_DEPLOY == "true"
      when: never
    - if: $NIGHTLY == "true" && $QA_DOCKER_DEPLOY == "true"
      when: never
    ## NOTE: QA docker image can be build (if no image on current dev) & deployed to Gitlab/NGC using CI only on dev branch.
    ## It can be built using Run pipeline page (https://gitlab-master.nvidia.com/clara-discovery/bionemo/-/pipelines)
    ## by clicking Run pipeline button and setting QA_DOCKER_DEPLOY=true
    ## Only docker build-bionemo-image stage and qa-deploy are executed. Pipeline with NIGHTLY=true cannot be executed.
    - if: $CI_COMMIT_BRANCH == "dev" && $CI_PIPELINE_SOURCE == "web" &&  $QA_DOCKER_DEPLOY == "true"
      variables:
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /SKIP_CI/
      variables:
        EXCLUDE_DOCKER_IMAGE_BUILD: "true"
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /JET_NOT_REQUIRED/
      variables:
        EXCLUDE_JET: "true"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    ## NOTE: Convergence test are run using JET via CI. They can be triggered from any branch but only from the Run pipeline page
    ## (https://gitlab-master.nvidia.com/clara-discovery/bionemo/-/pipelines) by clicking Run pipeline button and setting JET_CONV_TEST=true
    ## Only docker build-bionemo-image and jet stage using training definitions from JET_WORKLOAD_FOLDER is executed (docs build and pytest stages is disabled)
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $JET_CONV_TEST == "true"
      variables:
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_PYTEST: "true"
        JET_WORKLOAD_FOLDER: "partial-conv-trainings"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") && $PYTEST != "true" && $JET == "true"
      variables:
        EXCLUDE_PYTEST: "true"
        EXCLUDE_DOCS_BUILD: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST == "true" && $JET != "true"
      variables:
        EXCLUDE_JET: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST != "true" && $JET != "true"
      variables:
        EXCLUDE_PYTEST: "true"
        EXCLUDE_DOCS_BUILD: "true"
        EXCLUDE_JET: "true"
    - if: ($CI_PIPELINE_SOURCE == "web" || $CI_PIPELINE_SOURCE == "schedule") &&  $PYTEST == "true" && $JET == "true"
    - if: $CI_COMMIT_BRANCH == "dev" && $CI_PIPELINE_SOURCE == "push"
      variables:
        EXCLUDE_DEPLOY: "false"


.docker-setup:
  services:
    - docker:20.10.16-dind
  tags:
    - dind
  before_script:
    - until docker info; do sleep 1; done
    - mkdir -p $HOME/.docker
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker login -u '$oauthtoken' -p $NGC_CLI_API_KEY nvcr.io


code_format:
  stage: code_format
  rules:
    - if: $JET_CONV_TEST == "true"
      when: never
    - when: always
  script:
    - pre-commit run --all-files --show-diff-on-failure
  image: nvcr.io/nvidian/cvai_bnmo_trng/bionemo-linter:latest
  tags:
   - generic


license_check:
  image: python:3.10.13-slim
  stage: code_format
  tags:
   - generic
  script:
    - INFRA_BIONEMO_DEP=$(cat setup/requirements-dev.txt | grep "infra-bionemo==")
    - pip install --index-url "https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/api/v4/projects/118589/packages/pypi/simple" "${INFRA_BIONEMO_DEP}"
    - license-check -c .

build-bionemo-image:
  extends:
    - .docker-setup
  stage: build
  rules:
    - if: $EXCLUDE_DOCKER_IMAGE_BUILD == "true"
      when: never
    - when: on_success
  script:
    - df -h
    - if [[ $NIGHTLY = true ]]; then
      base="--build-arg BASE_IMAGE=$NEMO_NIGHTLY_IMAGE";
      else
      base="";
      fi
    # maybe we built this image on a previous pipeline run -- if so, we don't need to remake it!
    - docker pull ${IMAGE_NAME} || true
    # or maybe we built an image for the previous commit that we can use as a layer cache
    # TODO [mgreaves] There's no `git` in DIND :( Odd though -- how does it checkout the code!?
    #    - >
    #      for i in $(seq 1 10); do
    #        docker pull "${IMAGE_REPO_NAME}:$(git rev-parse HEAD~${i})" || true
    #      done
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?
    - docker build
      --network host ${base}
      --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
      --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
      --label com.nvidia.bionemo.created_at=${DATE}
      --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
      --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
      --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
      --secret id=GITLAB_TOKEN,env=RO_API_TOKEN
      -t "${IMAGE_NAME}"
      -f setup/Dockerfile .
    - df -h
    - docker push "${IMAGE_NAME}"
    # tag with short commit too
    - docker tag "${IMAGE_NAME}" "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}"
    - docker push "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}"
    # Re-tag with prior pipeline ID format for backwards compatability
    - docker tag "${IMAGE_NAME}" "${IMAGE_REPO_NAME}:${PIPELINE_TAG}"
    - docker push "${IMAGE_REPO_NAME}:${PIPELINE_TAG}"
    # Also tag this image with a format that uses the date of creation:
    #       YYYY-MM-DD--CCCCCCCC
    # Where 'C..C' are the first 8 characters of the commit
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    - TAG_DATE_SHORT_COMMIT="${CI_COMMIT_SHORT_SHA}--${DATE_YMD}"
    - docker tag "${IMAGE_NAME}" "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    - docker push "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    # For merge request branches only, also tag the image with the merge request number:
    #       mr--MMMM--YYYY-MM-DD--CCCCCCCC
    # Where 'M..M' is the merge request number. Note it is variable-sized.
    - TAG_MR="mr--${CI_MERGE_REQUEST_IID}--${TAG_DATE_SHORT_COMMIT}"
    - if [[ "${CI_MERGE_REQUEST_IID}" != "" ]]; then
      docker tag "${IMAGE_NAME}" "${IMAGE_REPO_NAME}:${TAG_MR}" && docker push "${IMAGE_REPO_NAME}:${TAG_MR}" && echo "MR docker tag:" "${IMAGE_REPO_NAME}:${TAG_MR}";
      fi
    #
    # FIXME [mgreaves] See note in internal/Dockerfile-devel about this (it is commented as another 'FIXME').
    #                  tl;dr Secuirty leak: passing in CI_JOB_TOKEN as a build-arg persists its value in the image!
    #
    # To fix, we'll need something like:
    #
    # - TPL_REPO=https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/dl/gwe/torch_performance_linter
    # - docker build
    #   --network host --no-cache
    #   --build-arg BIONEMO_IMAGE="$PIPELINE_TAG"
    #   --secret id=TPL_REPO,env=TPL_REPO
    #   -t ${IMAGE_NAME}${SUFFIX_DEV} -f internal/Dockerfile-devel .
    #
    # As in, ensure that the CI_JOB_TOKEN makes it way via --secret, not --build-arg.
    #
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?
    - docker build
      --network host
      --build-arg BIONEMO_IMAGE="$IMAGE_NAME"
      --build-arg TPL_REPO=https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab-master.nvidia.com/dl/gwe/torch_performance_linter
      --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
      --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
      --label com.nvidia.bionemo.created_at=${DATE}
      --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
      --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
      --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
      -t "${IMAGE_NAME}${SUFFIX_DEV}"
      -f internal/Dockerfile-devel .
    - df -h
    - docker push "${IMAGE_NAME}${SUFFIX_DEV}"
    # tag with short commit too
    - docker tag "${IMAGE_NAME}" "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}${SUFFIX_DEV}"
    - docker push "${IMAGE_REPO_NAME}:${CI_COMMIT_SHORT_SHA}${SUFFIX_DEV}"
    # Re-tag with prior pipeline ID format for backwards compatability
    - docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${IMAGE_REPO_NAME}:${PIPELINE_TAG}${SUFFIX_DEV}"
    - docker push "${IMAGE_REPO_NAME}:${PIPELINE_TAG}${SUFFIX_DEV}"
    # Re-tag with date & short commit too
    - docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
    - docker push "${IMAGE_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
    - if [[ "${CI_MERGE_REQUEST_IID}" != "" ]]; then
      docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${IMAGE_REPO_NAME}:${TAG_MR}${SUFFIX_DEV}" && docker push "${IMAGE_REPO_NAME}:${TAG_MR}${SUFFIX_DEV}";
      fi

build-docs-image:
  extends:
    - .docker-setup
  rules:
    - if: $EXCLUDE_DOCS_BUILD == "true"
      when: never
    - when: on_success
  stage: build
  script:
    - if [[ $NIGHTLY = true ]]; then
      base="--build-arg BASE_IMAGE=$NEMO_NIGHTLY_IMAGE";
      else
      base="";
      fi
    - cd docs/
    # CANNOT use date command -- busybox doesn't support --iso-8601
    # - DATE=$(date --iso-8601=seconds -u)
    # Good thing we have CI_PIPELINE_CREATED_AT !
    - DATE="${CI_PIPELINE_CREATED_AT}"
    - TAG_DATE="$(echo ${DATE} | cut -f1 -d'T')"
    # maybe we built this image on a previous pipeline run -- if so, we don't need to remake it!
    - docker pull ${IMAGE_NAME}${SUFFIX_DOCS} || true
    # or maybe we built an image for the previous commit(s) that we can use as a layer cache
    # TODO [mgreaves] There's no `git` in DIND :( Odd though -- how does it checkout the code!?
    #    - >
    #      for i in $(seq 1 10); do
    #        docker pull "${IMAGE_REPO_NAME}:$(git rev-parse HEAD~${i})${SUFFIX_DOCS}" || true
    #      done
    # TODO [mgreaves] This had --no-cache on it before. Why would we want this?
    - docker build
      --network host ${base}
      --label com.nvidia.bionemo.short_git_sha=${CI_COMMIT_SHORT_SHA}
      --label com.nvidia.bionemo.git_sha=${CI_COMMIT_SHA}
      --label com.nvidia.bionemo.created_at=${DATE}
      --label com.nvidia.bionemo.branch=${CI_COMMIT_BRANCH}
      --label com.nvidia.bionemo.pipeline_id=${CI_PIPELINE_ID}
      --label com.nvidia.bionemo.merge_request_id=${CI_MERGE_REQUEST_IID}
      -t "${IMAGE_NAME}${SUFFIX_DOCS}"
      -f Dockerfile.docs .
    - docker push "${IMAGE_NAME}${SUFFIX_DOCS}"
# Note: It is tempting to build the docs in the same job as build-docs-image, i.e. have a
# `docker run ... sphinx-build ...` command here, however getting the output of this build
# is non-trivial. It is non-trivial to mount volumes to docker commands when DIND is used in
# gitlab-ci, therefore we split the docs image build and docs build into separate jobs,
# where the latter doesn't require DIND.


build-docs:
  image:
    name: "${IMAGE_NAME}${SUFFIX_DOCS}"
    entrypoint: [ "" ]
  stage: build
  needs: [build-docs-image]
  tags:
    - generic
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  rules:
    - if: $EXCLUDE_DOCS_BUILD == "true"
      when: never
    - when: on_success
  script:
    # Build the docs, store as artifact in ${CI_PROJECT_DIR = /builds/clara-discovery/bionemo}.
    - mkdir -p /builds/clara-discovery/bionemo/docs_build
    - cd /docs
    - sphinx-build bionemo /builds/clara-discovery/bionemo/docs_build/html
  artifacts:
      paths:
        - docs_build
      expire_in: 1 week

.common_pytest_before_script: &common_before_script
  before_script:
    - nvidia-smi
    - df -Thl
    - pwd
    - echo $BIONEMO_HOME
    - ls $BIONEMO_HOME
    - mkdir -p /builds/bionemo/
    - cp -av $BIONEMO_HOME /builds/
    - rm /workspace/bionemo -rf
    - ln -s /builds/bionemo /workspace/bionemo
    - export BIONEMO_HOME=/builds/bionemo
    - echo $BIONEMO_HOME
    - cd $BIONEMO_HOME
    - ls -ltr
    - ls -lts /
    - df -Thl

pytest:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    # TODO(trvachov): This install the NGC CLI, but this should be removed once all of our tests stop relying on data from NGC.
    - wget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.40.0/files/ngccli_linux.zip -O /tmp/ngccli_linux.zip && unzip /tmp/ngccli_linux.zip -d /tmp/ && export PATH=$PATH:/tmp/ngc-cli
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - python download_models.py openfold_initial_training_public openfold_finetuning_4_public openfold_initial_training_inhouse openfold_finetuning_inhouse esm2nv_3b esm2nv_650m esm2nv_8m_lora esm2nv_8m_untrained diffdock_confidence diffdock_score equidock_db5 equidock_dips megamolbart molmim_70m_24_3 prott5nv esm1nv dnabert geneformer_31M_240430 --source pbss --download_dir $MODEL_PATH --verbose
    - unzip examples/tests/test_data/uniref202104_esm2_qc_test200_val200.zip -d examples/tests/test_data/
    - bash ./examples/molecule/diffdock/scripts/download_data_sample.sh -data_path $BIONEMO_HOME/examples/tests/test_data/molecule/diffdock/ -pbss
    - bash ./examples/protein/openfold/scripts/download_data_sample.sh -data_path $BIONEMO_HOME/examples/tests/test_data/ -pbss
    - bash ./examples/singlecell/geneformer/scripts/download_sample_data.sh -data_path $BIONEMO_HOME/examples/tests/test_data
    - ls examples/tests/test_data/uniref202104_esm2_qc_test200_val200
    - rm -rf ./.pytest_cache/
    - mkdir -p ${CI_PROJECT_DIR}/heatmaps
    - pytest -m "not internal and not needs_fork and not needs_80gb_memory_gpu" -vv --durations=0 --cov=bionemo --cov-report term --cov-report xml:coverage.xml -k "not test_model_training" | tee pytest_report.log
    # Compute test coverage with higher precision, i.e. up to 2 decimal digits. (In the logs, we'll have 8 decimal digits.)
    # From "TOTAL ${TOTAL STATEMENTS} ${NON-COVERED STATEMENTS} ${COVERAGE PERCENT}", compute (${TOTAL STATEMENTS} - ${NON-COVERED STATEMENTS}) / ${TOTAL STATEMENTS}.
    - cat pytest_report.log | grep -Eo "TOTAL\s+[0-9]+\s+[0-9]+\s+[0-9]+%" | python -c 'import sys; lines=sys.stdin.readline(); x = lines.split(); n = int(x[1]) - int(x[2]); print(f"BIONEMO TEST COVERAGE = {100 * n / int(x[1]):.8f}%")'
    - cp -rv ${BIONEMO_HOME}/tests/data/esm2_golden_values/heatmaps ${CI_PROJECT_DIR}/heatmaps
    - cp ${BIONEMO_HOME}/coverage.xml ${CI_PROJECT_DIR}
    - df -Thl
    - if [ ! -e "${CI_PROJECT_DIR}/coverage.xml" ]; then echo "${CI_PROJECT_DIR}/coverage.xml does not exist. Failing..."; exit 1; fi
  coverage: '/BIONEMO TEST COVERAGE = ([0-9]+\.*[0-9]*%)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        # Relative path in ${CI_PROJECT_DIR}...
        path: coverage.xml
    paths:
      - heatmaps



pytest-fork:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - python download_models.py openfold_finetuning_inhouse esm2nv_3b esm2nv_650m diffdock_confidence diffdock_score equidock_db5 equidock_dips megamolbart prott5nv molmim_70m_24_3 geneformer_31M_240430 esm1nv dnabert --source pbss --download_dir $MODEL_PATH --verbose
    - unzip examples/tests/test_data/uniref202104_esm2_qc_test200_val200.zip -d examples/tests/test_data/
    - bash ./examples/molecule/diffdock/scripts/download_data_sample.sh -data_path $BIONEMO_HOME/examples/tests/test_data/molecule/diffdock/ -pbss
    - bash ./examples/protein/openfold/scripts/download_data_sample.sh -data_path $BIONEMO_HOME/examples/tests/test_data/ -pbss
    - bash ./examples/singlecell/geneformer/scripts/download_sample_data.sh -data_path $BIONEMO_HOME/examples/tests/test_data
    # unit tests which need to be run in a separate process
    - bash internal/run_pytest_fork.sh
    - df -Thl


pytest-internal:
  extends:
    - .common_pytest_before_script
  image:
    name: "${IMAGE_NAME}${SUFFIX_DEV}"
    entrypoint: [ "" ]
  stage: test
  allow_failure: false
  rules:
    - if: $EXCLUDE_PYTEST == "true"
      when: never
    - when: on_success
  tags:
    - gpu
  variables:
    GIT_STRATEGY: none
    GIT_CHECKOUT: "false"
  script:
    - export NGC_CLI_ORG NGC_CLI_TEAM NGC_CLI_FORMAT_TYPE NGC_CLI_API_KEY
    - export AWS_ENDPOINT_URL=https://pbss.s8k.io
    - export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY
    - export MODEL_PATH=${BIONEMO_HOME}/models
    - python download_models.py esm2_650m_huggingface esm2_3b_huggingface --source pbss --download_dir $MODEL_PATH --verbose
    - echo "Checking test data contents..."
    - rm -rf ./.pytest_cache/
    - pytest -m "internal" -v --durations=0 --cov=bionemo --cov-report term --cov-report xml:coverage.xml -k "not test_model_training"
    - df -Thl


.jet-configure:
  stage: jet
  tags:
    - generic
  needs:
    - job: build-bionemo-image
    - job: pytest
      optional: true
  after_script:
    - echo "JET_WORKLOADS_PROJECT=$CI_PROJECT_ID" >> jet.env
    - echo "JET_WORKLOADS_JOB=$CI_JOB_ID" >> jet.env
  artifacts:
    reports:
      dotenv: jet.env


jet-configure:
  extends: [.jet-configure]
  variables:
    JET_WORKLOADS_REF_BASE: "bionemo"
    JET_WORKLOADS_REF: "${JET_WORKLOADS_REF_BASE}/${CI_COMMIT_BRANCH}"
    WANDB_PROJECT_NAME_BASE: "jet--${JET_WORKLOAD_FOLDER}"
    WANDB_PROJECT_NAME: "${WANDB_PROJECT_NAME_BASE}--${CI_COMMIT_BRANCH}"
  artifacts:
    paths:
      - $JET_WORKLOADS_DIR
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $EXCLUDE_JET != "true"
      when: manual
      variables:
        JET_WORKLOADS_REF: "bionemo/merge_request_event"
    - when: on_success
  before_script:
    - apk update && apk add git yq
    - 'if [[ $CI_PIPELINE_SOURCE == "merge_request_event" ]]; then
      CUSTOM_BRANCH_NAME=$(echo "$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME" | tr "/" "__");
      else
      CUSTOM_BRANCH_NAME=$(echo "$CI_COMMIT_BRANCH" | tr "/" "__");
      fi'
    - export CUSTOM_BRANCH_NAME
  script:
    - yq e ".spec.source.image = \"${IMAGE_NAME}\"" -i ${JET_WORKLOADS_DIR}/builds/bionemo.yaml
    - 'find "$JET_WORKLOADS_DIR" -type f -name "*.yaml" -print0 | while IFS= read -r -d "" file; do
          echo "File: $file";
          yq e ".labels.workload_ref = \"${JET_WORKLOADS_REF}\"" -i ${file};
          yq e ".labels.bionemo_ci_pipeline_id = \"${CI_PIPELINE_ID}\"" -i ${file};
          yq e ".labels.bionemo_commit_sha = \"${CI_COMMIT_SHORT_SHA}\"" -i ${file};
          yq e ".spec.scope = \"${JET_WORKLOAD_FOLDER}\"" -i ${file};
          if [[ $JET_CONV_TEST = true ]] & [[ $file == *"recipe"* ]]; then   
            yq e ".spec.wandb_project_name = \"${WANDB_PROJECT_NAME_BASE}--${CUSTOM_BRANCH_NAME}\"" -i ${file};
            yq e ".spec.pipeline_label = \"${CI_PIPELINE_CREATED_AT}_${CI_COMMIT_SHORT_SHA}_${CI_PIPELINE_ID}\"" -i ${file};       
          fi;
          cat ${file};
       done'


.jet-trigger-template:
  stage: jet
  needs: [jet-configure]
  inherit:
    variables: false
  variables:
    JET_WORKLOADS_PROJECT: $JET_WORKLOADS_PROJECT
    JET_WORKLOADS_JOB: $JET_WORKLOADS_JOB
    JET_WORKLOADS_FILTER: type == 'recipe'
    JET_BUILDS_PLATFORMS: linux/amd64
  trigger:
    project: dl/jet/ci
    branch: bionemo # NOTE: this branch name enables running JET on Draco OCI
    strategy: depend


jet-trigger:
  extends: [.jet-trigger-template]
  variables:
    JET_API_TAG: v0.0.0-dev.14637274
    JET_CUSTOM_CONFIG: |
      restarter:
        enabled: true
        max_retries: 2
        retry_on: ['1.2.1.2']
        waiting_time: 60
      launchers:
        dgxa100_dracooci:
          additional_flags:
            deadline: now+42hours
  inherit:
    variables:
      - EXCLUDE_JET
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - when: on_success


jet-test:
  needs: [jet-trigger]
  rules:
    - if: $EXCLUDE_JET == "true"
      when: never
    - when: on_success
  image:
    name: gitlab-master.nvidia.com:5005/dl/jet/api:latest
    entrypoint: [ "" ]
  tags:
    - generic
  stage: jet
  before_script:
    - export RO_API_TOKEN CI_PROJECT_ID CI_PIPELINE_ID GITLAB_USER_LOGIN CI_JOB_JWT
    - jet secrets jwt-login jwt/nvidia/gitlab-master bionemo-ci $CI_JOB_JWT
  script:
    - pip install tqdm
    - echo "CI_PROJECT_ID=${CI_PROJECT_ID}, CI_PIPELINE_ID=${CI_PIPELINE_ID}"
    - bash $CI_PROJECT_DIR/internal/jet/scripts/run_jet_test.sh


qa-deploy:
  stage: deploy
  extends:
    - .docker-setup
  rules:
    - if: $QA_DOCKER_DEPLOY == "true"
  script:
    - docker pull "${IMAGE_NAME}"
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    # QA image tag has format that uses the branch, date of creation & :
    #       BBBB--YYYY-MM-DD--CCCCCCCC-qa
    # Where 'C..C' are the first 8 characters of the commit
    # Where 'B...B' is the branch name. (Note: rules filter out invalid branch names!)
    - IMAGE_TAG_QA="${CI_COMMIT_BRANCH}--${DATE_YMD}--${CI_COMMIT_SHA}${SUFFIX_QA}"
    - IMAGE_NAME_QA="${IMAGE_REPO_NAME}:${IMAGE_TAG_QA}"
    - docker tag "${IMAGE_NAME}" "${IMAGE_NAME_QA}"
    - docker push "${IMAGE_NAME_QA}"
    - NGC_IMAGE_NAME_QA="${NGC_REPO_NAME}:${IMAGE_TAG_QA}"
    - docker tag "${IMAGE_NAME}" "${NGC_IMAGE_NAME_QA}"
    - docker push "${NGC_IMAGE_NAME_QA}"


dev-deploy:
  extends:
    - .docker-setup
  stage: deploy
  dependencies: [ ]
  rules:
    - if: $EXCLUDE_DEPLOY == "true"
      when: never
    - when: on_success
  before_script:
    - !reference [ .docker-setup, before_script ]
    - apk update && apk add curl
  script:
    # Get the images that we need to re-tag and publish on other image registries.
    - docker pull "${IMAGE_NAME}"
    - docker pull "${IMAGE_NAME}${SUFFIX_DEV}"
    # NOTE: CANNOT use date command -- busybox doesn't support --iso-8601
    # - DATE=$(date --iso-8601=seconds -u)
    # This is why we use the gitlab CI date env var.
    #
    # Push FW image to NGC
    - docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${IMAGE_TAG}"
    - docker push "${NGC_REPO_NAME}:${IMAGE_TAG}"
    # Also tag this image with a format that uses the branch & date of creation*:
    #       BBBB--YYYY-MM-DD--CCCCCCCC
    # Where 'C..C' are the first 8 characters of the commit
    # Where 'B...B' is the branch name. (Note: rules filter out invalid branch names!)
    # *NOTE: the branch name is included IFF it is "main" or "dev"
    #        otherwise, the first part -- "BBBB---" -- is **NOT** included!
    - DATE_YMD="$(echo ${DATE} | cut -f1 -d'T')"
    - TAG_DATE_SHORT_COMMIT="${CI_COMMIT_SHORT_SHA}--${DATE_YMD}"
    - docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    - docker push "${NGC_REPO_NAME}:${TAG_DATE_SHORT_COMMIT}"
    # Push -devel image to NGC too
    - docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${NGC_REPO_NAME}:${CI_COMMIT_SHA}${SUFFIX_DEV}"
    - docker push "${NGC_REPO_NAME}:${CI_COMMIT_SHA}${SUFFIX_DEV}"
    # also, MAYBE tag w/ branch name and push
    - >
      if [[ "${CI_COMMIT_BRANCH}" == "main" || "${CI_COMMIT_BRANCH}" == "dev" ]]; then
        TAG_BRANCH_DATE_SHORT_COMMIT="${CI_COMMIT_BRANCH}--${TAG_DATE_SHORT_COMMIT}"
        # main image
        docker tag "${IMAGE_NAME}" "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}"
        docker push "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}"
        # -devel image
        docker tag "${IMAGE_NAME}${SUFFIX_DEV}" "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
        docker push "${NGC_REPO_NAME}:${TAG_BRANCH_DATE_SHORT_COMMIT}${SUFFIX_DEV}"
      fi

