# @package _global_
defaults:
  - /base
  - _self_

job_name: amplify-recipes
resource_shape: gpu.2xh200

dashboard_info:
  model: geneformer
  variant: recipes
  repo: recipes

# Base configuration
recipe_subdir: amplify_accelerate_te_fp8
branch: jwilber/add-wandb-recipe-amplify
train_cmnd: train

wandb_init_args:
  mode: "online" # need online to collect logs; if offline, must manually sync after run

stop_after_n_steps: 10

trainer:
  report_to: "wandb"

# Run one for each config
products:
  - model_name: amplify_120M_sanity
    config: L0_sanity
  # - model_name: L1-350M-partial-conv
  #   config: L1_350M_partial_conv

script: |
  git clone https://github.com/NVIDIA/bionemo-framework.git
  if [ "${branch}" != "main" ]; then
    cd bionemo-framework
    git checkout "${branch}"
    cd ..
  fi
  cd bionemo-framework/recipes/${recipe_subdir}
  pip install -r requirements.txt
  torchrun ${train_cmnd}.py \
    --config-name ${config}.yaml \
    stop_after_n_steps=${stop_after_n_steps} \
    trainer.report_to=${trainer.report_to}
