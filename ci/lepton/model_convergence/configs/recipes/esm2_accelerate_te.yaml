# @package _global_
defaults:
  - /base
  - _self_

resource_shape: gpu.2xh100-sxm
node_group: yo-bom-lepton-001

wandb_init_args:
  project: "lepton_recipe_convergence_${sanitize:${branch}}"
  group: "${recipe_subdir}_${resource_shape}"
  mode: "online"

recipe_subdir: esm2_accelerate_te

train_cmd: train
stop_after_n_steps: 100

# todo: use L1 configs, esm2 3B, focus on 1B.
# future: amplify;
products:
  - config: L0_sanity

trainer:
  report_to: "wandb"

train_script: |
  accelerate launch --config_file accelerate_config/default.yaml \
    ${train_cmd}.py \
    --config-name=${config} \
    stop_after_n_steps=${stop_after_n_steps} \
    wandb_init_args.mode=${wandb_init_args.mode} \
    +wandb_init_args.project=${wandb_init_args.project} \
    +wandb_init_args.group=${wandb_init_args.group}
