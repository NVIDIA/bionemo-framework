job_name: test-new-job
resource_shape: gpu.2xh200
node_group_name: nv-int-multiteam-nebius-h200-01
container:
  image: nvcr.io/nvidian/cvai_bnmo_trng/bionemo:esm2-native-te-nvfsdp-0725
  registry_auth: lepton-nvidia-cvai-bnmo-trng
environment_variables:
- name: WANDB_API_KEY
  value: JWILBER_WANDB_API_KEY
model_name: esm2_t33_650M_UR50D
num_train_steps: 15
script: "#!/bin/bash\n# Download the environment setup script from Lepton's GitHub\
  \ repository, make it executable, and source it to initialize the environment variables.\n\
  wget -O init.sh https://raw.githubusercontent.com/leptonai/scripts/main/lepton_env_to_pytorch.sh\n\
  chmod +x init.sh\nsource init.sh\n\nGPUS_PER_NODE=$(nvidia-smi -L | wc -l)\n\ntorchrun\
  \ \\\n  --rdzv_id $LEPTON_JOB_NAME \\\n  --rdzv_backend c10d \\\n  --rdzv_endpoint\
  \ $MASTER_ADDR:$MASTER_PORT \\\n  --nproc-per-node $GPUS_PER_NODE \\\n  --nnodes\
  \ $NNODES \\\n  --node-rank $NODE_RANK \\\n  train.py --config-name L1_15B_perf_test\
  \ \\\n  model_name=${model_name} \\\n  num_train_steps=${num_train_steps}\n"
