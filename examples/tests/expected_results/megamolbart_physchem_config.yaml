name: mmb_physchem
do_training: true
do_testing: true
seed: 42
restore_from_path: ${oc.env:BIONEMO_HOME}/models/molecule/megamolbart/megamolbart.nemo
trainer:
  devices: 1
  num_nodes: 1
  precision: 16
  accelerator: gpu
  max_epochs: 50
  max_steps: 20
  log_every_n_steps: 100
  val_check_interval: 8
  num_sanity_val_steps: 2
  limit_train_batches: 1.0
  limit_val_batches: 1
  limit_test_batches: 1
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  logger: false
  enable_checkpointing: false
  replace_sampler_ddp: false
model:
  name: small_span_aug
  micro_batch_size: 32
  global_batch_size: null
  tensor_model_parallel_size: 1
  pipeline_model_parallel_size: 1
  resume_from_checkpoint: null
  pipeline_model_parallel_split_rank: 0
  make_vocab_size_divisible_by: 128
  pre_process: true
  post_process: false
  megatron_amp_O2: false
  seq_length: 512
  max_position_embeddings: ${.seq_length}
  num_layers: 6
  hidden_size: 512
  ffn_hidden_size: ${multiply:${model.hidden_size}, 4}
  num_attention_heads: 8
  init_method_std: 0.02
  hidden_dropout: 0.1
  attention_dropout: 0.1
  position_embedding_type: learned_absolute
  relative_position_bias_self_attention_only: true
  relative_attention_num_buckets: 32
  relative_attention_max_distance: 128
  kv_channels: null
  apply_query_key_layer_scaling: true
  layernorm_epsilon: 1.0e-05
  persist_layer_norm: true
  gradient_as_bucket_view: true
  bias_gelu_fusion: true
  masked_softmax_fusion: true
  bias_dropout_add_fusion: true
  bias: true
  normalization: layernorm
  encoder_arch: transformer
  decoder_arch: transformer
  activation: gelu
  headscale: false
  share_token_embeddings: true
  share_decoder_tokens_head_embeddings: false
  tokenizer:
    library: regex
    type: null
    model: ${oc.env:BIONEMO_HOME}/tokenizers/molecule/megamolbart/vocab/megamolbart.model
    vocab_file: ${oc.env:BIONEMO_HOME}/tokenizers/molecule/megamolbart/vocab/megamolbart.vocab
    merge_file: null
  data:
    links_file: ${oc.env:BIONEMO_HOME}/examples/molecule/megamolbart/dataset/PhysChem-downloader.txt
    dataset_path: ${oc.env:BIONEMO_HOME}/examples/tests/test_data/molecule/physchem/${model.data.task_name}
    dataset:
      train: x000
      test: x000
      val: x000
    encoder_augment: true
    encoder_mask: true
    decoder_augment: true
    decoder_mask: false
    mask_prob: 0.1
    span_lambda: 3.0
    micro_batch_size: ${model.micro_batch_size}
    num_workers: 0
    dataloader_type: single
    canonicalize_input: true
    max_seq_length: ${model.seq_length}
    seed: ${seed}
    skip_lines: 0
    drop_last: false
    pin_memory: false
    index_mapping_dir: null
    data_impl: csv_mmap
    data_impl_kwargs:
      csv_mmap:
        newline_int: 10
        header_lines: 1
        workers: ${model.data.num_workers}
        sort_dataset_paths: true
        data_sep: ','
        data_col: 1
    use_upsampling: true
    split_data: true
    val_frac: 0.15
    test_frac: 0.15
    task_name: SAMPL
    task_type: regression
    sequence_column: smiles
    target_column: expt
    emb_batch_size: ${model.micro_batch_size}
  optim:
    name: fused_adam
    lr: 1.0
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.01
    sched:
      name: NoamAnnealing
      d_model: ${model.hidden_size}
      warmup_steps: 8000
      warmup_ratio: null
      max_steps: 1000000
      min_lr: 1.0e-05
  dwnstr_task_validation:
    enabled: false
    dataset:
      class: bionemo.model.core.dwnstr_task_callbacks.SingleValuePredictionCallback
      task_type: regression
      infer_target: bionemo.model.molecule.megamolbart.infer.MegaMolBARTInference
      max_seq_length: ${model.seq_length}
      emb_batch_size: 128
      batch_size: 128
      num_epochs: 10
      shuffle: true
      num_workers: 8
      dataset_path: ${oc.env:BIONEMO_HOME}/data/physchem/${model.dwnstr_task_validation.dataset.task_name}
      task_name: SAMPL
      dataset:
        train: x000
        test: x000
      sequence_column: smiles
      target_column: expt
      random_seed: 1234
      optim:
        name: adam
        lr: 0.0001
        betas:
        - 0.9
        - 0.999
        eps: 1.0e-08
        weight_decay: 0.01
        sched:
          name: WarmupAnnealing
          min_lr: 1.0e-05
          last_epoch: -1
          warmup_ratio: 0.01
          max_steps: 1000
  encoder_frozen: true
  downstream_task:
    n_outputs: 1
    hidden_layer_size: 128
    loss_func: MSELoss
  finetuning_optim:
    name: adam
    lr: 0.001
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.01
    sched:
      name: WarmupAnnealing
      min_lr: 1.0e-05
      last_epoch: -1
      warmup_steps: 100
exp_manager:
  name: ${name}
  resume_if_exists: true
  resume_ignore_no_checkpoint: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    save_top_k: 3
    monitor: val_loss
    mode: min
    save_last: true
    always_save_nemo: true
    filename: ${name}-${model.name}--{val_loss:.2f}-{step}-{consumed_samples}
    model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}
  exp_dir: ${oc.env:BIONEMO_HOME}/results/nemo_experiments/${.name}/${.wandb_logger_kwargs.name}
  explicit_log_dir: ${.exp_dir}
  create_wandb_logger: false
  create_tensorboard_logger: false
  wandb_logger_kwargs:
    project: ${name}_finetuning
    name: ${name}_finetuning_encoder_frozen_${model.encoder_frozen}
    group: ${model.name}
    job_type: Localhost_nodes_${trainer.num_nodes}_gpus_${trainer.devices}
    notes: 'date: ${now:%y%m%d-%H%M%S}'
    tags:
    - ${name}
    - ${model.name}
    offline: false
target: bionemo.model.molecule.megamolbart.MegaMolBARTModel
infer_target: bionemo.model.molecule.megamolbart.infer.MegaMolBARTInference
