defaults:
  - pretrain_esm2_8M

hydra:
  searchpath:
    - file://${oc.env:BIONEMO_HOME}/examples/protein/esm2nv/conf

trainer:
  devices: 1
  num_nodes: 1
  max_epochs: 1 # PTL default. In practice we don't usually train for more than 1 epoch.
  max_steps: 500 # consumed_samples = global_step * micro_batch_size * data_parallel_size * accumulate_grad_batches
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  val_check_interval: 1.0
  check_val_every_n_epoch: 1

model:
  data:
    dataset_path: ${oc.env:BIONEMO_HOME}/examples/tests/test_data/uniref202104_esm2_qc_test200_val200
    train:
      uf90_datapath: ${model.data.dataset_path}/ur90_ur50_sampler.fasta
      cluster_mapping_tsv: ${model.data.dataset_path}/mapping.tsv
  dwnstr_task_validation:
    dataset:
      emb_batch_size: 24
      batch_size: ${.emb_batch_size}
      num_epochs: 1
      task_name: downstream
      dataset_path: ${oc.env:BIONEMO_HOME}/examples/tests/test_data/protein/downstream


exp_manager:
  exp_dir: ${oc.env:BIONEMO_HOME}/test_results/nemo_experiments/esm2nv_pretrain
  create_wandb_logger: False
  create_tensorboard_logger: False
  create_checkpoint_callback: False
  resume_if_exists: False
  wandb_logger_kwargs:
    offline: True
