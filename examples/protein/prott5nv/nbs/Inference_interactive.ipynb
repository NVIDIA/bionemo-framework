{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1390789",
   "metadata": {},
   "source": [
    "# Inference Sample for ProtT5nv\n",
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "**Before diving in, ensure you have all [necessary prerequisites](https://docs.nvidia.com/bionemo-framework/latest/pre-reqs.html). If this is your first time using BioNeMo, we recommend following the [quickstart guide](https://docs.nvidia.com/bionemo-framework/latest/quickstart-fw.html) first.** \n",
    "\n",
    "Additionally, this notebook assumes you have started a [local inference server](https://docs.nvidia.com/bionemo-framework/latest/inference-triton-fw.html) using a pretrained [Prot-T5](https://docs.nvidia.com/bionemo-framework/latest/models/prott5nv.html) model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f0ebb950ce6a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "try:\n",
    "    BIONEMO_HOME: Path = Path(os.environ['BIONEMO_HOME']).absolute()\n",
    "except KeyError:\n",
    "    print(\"Must have BIONEMO_HOME set in the environment! See docs for instructions.\")\n",
    "    raise\n",
    "\n",
    "config_path = BIONEMO_HOME / \"examples\" / \"protein\" / \"prott5nv\" / \"conf\"\n",
    "print(f\"Using model configuration at: {config_path}\")\n",
    "assert config_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ede76d",
   "metadata": {},
   "source": [
    "### Setup and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\n",
    "    'MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL', \n",
    "    'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbba5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.utils import load_model_config\n",
    "\n",
    "cfg = load_model_config(config_path, config_name=\"infer.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bionemo.model.loading import setup_inference\n",
    "# inferer, trainer, dataloader = setup_inference(cfg, interactive=True)\n",
    "# NEEDS the data for the trainer & dataloader\n",
    "# i.e. needs /workspace/bionemo/data/FLIP\n",
    "from bionemo.triton.utils import load_model_for_inference\n",
    "from bionemo.model.protein.prott5nv.infer import ProtT5nvInference\n",
    "\n",
    "inferer = load_model_for_inference(cfg, interactive=True)\n",
    "\n",
    "print(f\"Loaded a {type(inferer)}\")\n",
    "assert isinstance(inferer, ProtT5nvInference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986e73b",
   "metadata": {},
   "source": [
    "### Sequence to Hidden States\n",
    "\n",
    "__`seq_to_hiddens`__ queries the model to fetch the encoder hiddens states for the input protein sequence. `pad_mask` is returned with `hidden_states` and contains padding information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6416359",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = inferer.seq_to_hiddens(seqs)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "assert tuple(hidden_states.shape) == (2, 41, 768)\n",
    "assert tuple(pad_masks.shape) == (2, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fddc8d8",
   "metadata": {},
   "source": [
    "### Hidden States to Embedding\n",
    "\n",
    "__`hiddens_to_embedding`__ computes embedding vector by averaging `hidden_states` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36056230",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6077721",
   "metadata": {},
   "source": [
    "### Sequence to Embedding\n",
    "\n",
    "__`seq_to_embedding`__  queries the model to fetch the encoder hiddens states and computes embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92688727",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = inferer.seq_to_embeddings(seqs)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 768)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
