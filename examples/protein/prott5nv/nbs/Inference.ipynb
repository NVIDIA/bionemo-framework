{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7780edef",
   "metadata": {},
   "source": [
    "# Inference Sample for ProtT5nv\n",
    "\n",
    "Copyright (c) 2022, NVIDIA CORPORATION. Licensed under the Apache License, Version 2.0 (the \"License\") you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "- Linux OS\n",
    "- Pascal, Volta, Turing, or an NVIDIA Ampere architecture-based GPU.\n",
    "- NVIDIA Driver\n",
    "- Docker\n",
    "\n",
    "#### Import\n",
    "\n",
    "Components for inferencing are part of the BioNeMo ProtT5nv source code. This notebook demonstrates the use of these components.\n",
    "\n",
    "__`ProtT5nvInferenceWrapper`__ implements __`seq_to_embedding`__ function to obtain encoder embeddings for the input protein sequence in text format. \n",
    "\n",
    "Note that gRPC limits request size to 4MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bbae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer import ProtT5nvInferenceWrapper\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a4ddf",
   "metadata": {},
   "source": [
    "### Setup and Test Data\n",
    "\n",
    "__`ProtT5nvInferenceWrapper`__ is an adaptor that allows interaction with inference service.\n",
    "\n",
    "<u>Please note</u>: The batch size ot the number of sequences submitted for embedding inferencing (in other words, inference throughput) may be limited by the compute capacity of the inferencing node hosting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f55e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = ProtT5nvInferenceWrapper()\n",
    "\n",
    "seqs = ['MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL', 'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9945e",
   "metadata": {},
   "source": [
    "### Sequence to Embedding\n",
    "\n",
    "__`seq_to_embedding`__ queries the model to fetch the encoder embedding for the input protein sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98143bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 41, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = connection.seq_to_embedding(seqs)\n",
    "embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
