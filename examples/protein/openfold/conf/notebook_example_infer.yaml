defaults:
  - base_config
  - _self_

# The following scripts assumes MSA for each sequence will be generated offline. Template hits can be generated
# dynamically, but this require additional software (HH-suite)

force: false  # overwrite inference output
restore_from_path: ${oc.env:BIONEMO_HOME}/models/protein/openfold/openfold_finetuning_inhouse_checkpoint.nemo  # user must provide a checkpoint to load
results_path: ${oc.env:BIONEMO_HOME}/test_results/openfold_inference # a directory where all predictions are stored
# either a list of sequences or a path to a FASTA file
sequences:
  - MDTAMQLKTSIGLITCRMNTQNNQIETILVQKRYSLAFSEFIHCHYSINANQGHLIKMFNNMTINERLLVKTLDFDRMWYHIWIETPVYELYHKKYQKFRKNWLLPDNGKKLISLINQAKGSGTLLWEIPKGKPKEDESDLTCAIREFEEETGITREYYQILPEFKKSMSYFDGKTEYKHIYFLAMLCKSLEEPNMNLSLQYENRIAEISKISWQNMEAVRFISKRQSFNLEPMIGPAFNFIKNYLRYKH # 7DNU_A

seq_names: # Optional. If not provided, sequences will be named with consecutive indices
  - first_sequence

model:
  downstream_task:
    outputs: []  # Optional features to dump for downstream tasks.
    # Common options: single, msa, pair and sm_single.

  stage: finetuning #In this context the model is being fine-tuned from a base model or inference is performed. 
                    # also be set to intitial_training. 
  precision: tf32  # default precision in the model
  seed: 44 #random seed for initialization 
  micro_batch_size: 1 #batch size in the model at inference
  tensor_model_parallel_size: 1 #refer to train/fine tune
  pipeline_model_parallel_size: 1 #refer to train/fine tune
  resume_from_checkpoint: null # This is the path of the model checkpoint to resume from. If set to null 
                               # it is set to the checkpoint file specified in restore_from_path.

  # override from basic config
  max_msa_clusters: 508 # Maximal number of clusters in the MSA
  max_extra_msa: 5120 # The number of unclustered MSA sequences. See algorithm 8 in the alphafold paper. 
  use_only_pdb_chain_ids: null #Optional pdb chains to use 

  extra_msa_stack_config: # See algorithm 18
    chunk_size_msa_att: 1024 #Optional chunk size for a batch-like dimension in MSA attention.
    chunk_size_opm: 128 # Optional chunk size for a batch-like dimension in outer product mean.

  data:
    dataset_path: ${oc.env:BIONEMO_HOME}/examples/tests/test_data/openfold_data/ #path to the dataset
    dataset_variant: processed # Currently only processed data is supported. 
    msa_a3m_filepaths: # Optional list of MSAs files in A3M format for each sequence. Path should be null for sequences without MSAs.
      - - ${model.data.dataset_path}/inference/msas/7dnu_A/bfd_uniclust_hits.a3m
        - ${model.data.dataset_path}/inference/msas/7dnu_A/mgnify_hits.a3m
        - ${model.data.dataset_path}/inference/msas/7dnu_A/uniref90_hits.a3m
    template_hhr_filepaths: null # Optional list of structural templates for each sequence. Path should be null for sequences without strucutural homologues.
    # Effectively this argument will take a form of a list of lists.
    generate_templates_if_missing: False # If sequence have no provided hhr files, generate hits on-the-fly through hhsearch over pdb70 database
    pdb70_database_path: null # Path to pdb70 database. Only required when generate_templates_if_missing is true.
    num_workers: 0
    filter_by_alignments: True # Whether to filter out mmcif chains with no alignments. This can happen especially since pdb database changes and is not
    # easily versionable. For sanity checking, please set this to False and verify there is no more than couple hundreds of pdbs without alignment.

trainer:
  # the effective batch size should be 128
  devices: 1
  accelerator : gpu
  precision: 32
  num_nodes: 1
  logger: False

exp_manager:
  explicit_log_dir: null
  exp_dir: null
  create_checkpoint_callback: False
