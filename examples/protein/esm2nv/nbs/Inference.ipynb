{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5accdbca",
   "metadata": {},
   "source": [
    "# Inference Sample for ESM2\n",
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before diving in, please ensure that you have completed all steps in the [Getting Started](../../../../docs/bionemo/index.md) section.\n",
    "\n",
    "Additionally, this notebook assumes you have started a [local inference server](https://docs.nvidia.com/bionemo-framework/latest/inference-triton-fw.html) using a pretrained [ESM-2](https://docs.nvidia.com/bionemo-framework/latest/models/esm2-nv.html) model.\n",
    "\n",
    "\n",
    "To run this notebook, you must launch the PyTriton based model server script beforehand. See `bionemo.triton.inference_wrapper` for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f210ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bionemo.triton.inference_wrapper import new_inference_wrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d25dcf",
   "metadata": {},
   "source": [
    "### Setup and Test Data\n",
    "\n",
    "`new_inference_wrapper` creates a client that communicates with the Triton model server.\n",
    "\n",
    "Please note that the batch size (number of sequences submitted for embedding inference), in other words, inference throughput, may be limited by the compute capacity of the inference node hosting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b124fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = new_inference_wrapper(\"grpc://localhost:8001\")\n",
    "\n",
    "seqs = [\n",
    "    'MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL','MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eb8d3",
   "metadata": {},
   "source": [
    "### Sequence to Hidden States\n",
    "\n",
    "__`seq_to_hiddens`__ queries the model to fetch the encoder hiddens states for the input protein sequence. `enc_mask` is returned with `hidden_states` and contains padding information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde52a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, pad_masks = connection.seqs_to_hidden(seqs)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "assert tuple(hidden_states.shape) == (2, 43, 1280)\n",
    "assert tuple(pad_masks.shape) == (2, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130b163",
   "metadata": {},
   "source": [
    "### Hidden States to Embedding\n",
    "\n",
    "__`hiddens_to_embedding`__ computes embedding vector by averaging `hidden_states` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96409cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = connection.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f420f14",
   "metadata": {},
   "source": [
    "### Sequence to Embedding\n",
    "\n",
    "__`seq_to_embedding`__  queries the model to fetch the encoder hiddens states and computes embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = connection.seqs_to_embedding(seqs)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 1280)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
