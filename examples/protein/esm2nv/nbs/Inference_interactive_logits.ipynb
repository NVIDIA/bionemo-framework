{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ab51c8",
   "metadata": {},
   "source": [
    "# Inference Example for ESM2nv - Logit Sampling\n",
    "\n",
    "## Modified for logit/proba extraction\n",
    "Adrian Lange, A-Alpha Bio\n",
    "\n",
    "This notebook provides example code to extract ESM2nv logits from the language model head. Three example usages are also provided:\n",
    "\n",
    "1. Probability heatmap for each residue, argmax, posterior probability\n",
    "2. Infer probability of individual masked residues\n",
    "3. In-painting multiple masked residues\n",
    "\n",
    "---------------\n",
    "\n",
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "- Linux OS\n",
    "- Pascal, Volta, Turing, or an NVIDIA Ampere architecture-based GPU.\n",
    "- NVIDIA Driver\n",
    "- Docker\n",
    "\n",
    "#### Import\n",
    "\n",
    "Components for inferencing are part of the BioNeMo ESM source code. This notebook demonstrates the use of these components.\n",
    "\n",
    "__`ESMInferenceWrapper`__ implements __`seq_to_embedding`__ function to obtain encoder embeddings for the input protein sequence in text format. \n",
    "\n",
    "\n",
    "To run this notebook, you should launch the gRPC client in your terminal beforehand. \n",
    "\n",
    "The following command is an example of launching the gRPC inference client using the esm2-650M checkpoints:\n",
    "\n",
    "```python3 -m bionemo.model.protein.esm1nv.grpc.service --model esm2nv_650M```\n",
    "\n",
    "Note that gRPC limits request size to 4MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b772360c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a9f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from scipy.stats import gmean\n",
    "\n",
    "# For an optional visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a863931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model configuration at: /workspace/bionemo/examples/protein/esm2nv/conf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "try:\n",
    "    BIONEMO_HOME: Path = Path(os.environ['BIONEMO_HOME']).absolute()\n",
    "except KeyError:\n",
    "    print(\"Must have BIONEMO_HOME set in the environment! See docs for instructions.\")\n",
    "    raise\n",
    "\n",
    "config_path = BIONEMO_HOME / \"examples\" / \"protein\" / \"esm2nv\" / \"conf\"\n",
    "print(f\"Using model configuration at: {config_path}\")\n",
    "assert config_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d1a02",
   "metadata": {},
   "source": [
    "### Setup and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d596aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\n",
    "    'MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL', \n",
    "    'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b25e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2023.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from bionemo.triton.utils import load_model_config\n",
    "\n",
    "# Load the slightly modified inference config for working with the language model head\n",
    "cfg = load_model_config(config_path, config_name=\"infer_logits.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce7be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-23 15:48:12 utils:426] pytorch DDP is not initialized. Initializing with pytorch-lightening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-23 15:48:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-23 15:48:12 utils:277] Restoring model from /workspace/bionemo/models/protein/esm2nv/esm2nv_3B_converted.nemo\n",
      "[NeMo I 2024-08-23 15:48:12 utils:281] Loading model class: bionemo.model.protein.esm1nv.esm1nv_model.ESM2nvModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-23 15:48:12 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive mode selected, using strategy='auto'\n",
      "[NeMo I 2024-08-23 15:48:12 exp_manager:374] Experiments will be logged at /workspace/bionemo/examples/protein/esm2nv/nemo_experiments/ESM2nv_Inference/2024-08-23_15-48-12\n",
      "[NeMo I 2024-08-23 15:48:12 exp_manager:797] TensorboardLogger has been set up\n",
      "[NeMo I 2024-08-23 15:48:12 utils:250] \n",
      "    \n",
      "    ************** Trainer configuration ***********\n",
      "[NeMo I 2024-08-23 15:48:12 utils:251] \n",
      "    name: ESM2nv_Inference\n",
      "    desc: Minimum configuration for initializing a ESM2nv model for inference.\n",
      "    trainer:\n",
      "      precision: 16\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      accelerator: gpu\n",
      "      logger: null\n",
      "      accumulate_grad_batches: 1\n",
      "    exp_manager:\n",
      "      explicit_log_dir: null\n",
      "      exp_dir: null\n",
      "      name: ${name}\n",
      "      create_checkpoint_callback: false\n",
      "    model:\n",
      "      micro_batch_size: ${model.data.batch_size}\n",
      "      tensor_model_parallel_size: 1\n",
      "      pipeline_model_parallel_size: 1\n",
      "      seq_length: 1024\n",
      "      max_position_embeddings: 1024\n",
      "      encoder_seq_length: 1024\n",
      "      num_layers: 36\n",
      "      hidden_size: 2560\n",
      "      ffn_hidden_size: 10240\n",
      "      num_attention_heads: 40\n",
      "      init_method_std: 0.02\n",
      "      hidden_dropout: 0\n",
      "      kv_channels: null\n",
      "      apply_query_key_layer_scaling: true\n",
      "      layernorm_epsilon: 1.0e-05\n",
      "      make_vocab_size_divisible_by: 128\n",
      "      pre_process: true\n",
      "      post_process: true\n",
      "      bert_binary_head: false\n",
      "      resume_from_checkpoint: null\n",
      "      masked_softmax_fusion: true\n",
      "      tokenizer:\n",
      "        library: huggingface\n",
      "        type: BertWordPieceLowerCase\n",
      "        model: null\n",
      "        vocab_file: null\n",
      "        merge_file: null\n",
      "        mask_id: 32\n",
      "        model_name: facebook/esm2_t36_3B_UR50D\n",
      "        vocab_path: null\n",
      "        model_path: null\n",
      "      native_amp_init_scale: 4294967296\n",
      "      native_amp_growth_interval: 1000\n",
      "      fp32_residual_connection: false\n",
      "      fp16_lm_cross_entropy: false\n",
      "      seed: 1234\n",
      "      use_cpu_initialization: false\n",
      "      onnx_safe: false\n",
      "      activations_checkpoint_method: null\n",
      "      activations_checkpoint_num_layers: 1\n",
      "      data:\n",
      "        ngc_registry_target: uniref50_2022_05\n",
      "        ngc_registry_version: v23.06\n",
      "        data_prefix: ''\n",
      "        num_workers: 4\n",
      "        dataloader_type: single\n",
      "        reset_position_ids: false\n",
      "        reset_attention_mask: false\n",
      "        eod_mask_loss: false\n",
      "        masked_lm_prob: 0.15\n",
      "        short_seq_prob: 0.1\n",
      "        skip_lines: 0\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "        index_mapping_dir: null\n",
      "        data_impl: ''\n",
      "        data_impl_kwargs:\n",
      "          csv_mmap:\n",
      "            header_lines: 1\n",
      "            newline_int: 10\n",
      "            workers: 10\n",
      "            sort_dataset_paths: true\n",
      "            data_sep: ','\n",
      "            data_col: 3\n",
      "          csv_fields_mmap:\n",
      "            newline_int: 10\n",
      "            header_lines: 1\n",
      "            workers: null\n",
      "            sort_dataset_paths: false\n",
      "            data_sep: ','\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "          fasta_fields_mmap:\n",
      "            data_fields:\n",
      "              id: 0\n",
      "              sequence: 1\n",
      "        use_upsampling: true\n",
      "        seed: 1234\n",
      "        max_seq_length: 1024\n",
      "        dataset_path: ${oc.env:BIONEMO_HOME}/data/FLIP/secondary_structure/test/x000\n",
      "        dataset:\n",
      "          train: x[000..049]\n",
      "          test: x[000..049]\n",
      "          val: x[000..049]\n",
      "        micro_batch_size: 32\n",
      "        global_batch_size: null\n",
      "        modify_percent: 0.1\n",
      "        perturb_percent: 0.5\n",
      "        batch_size: 32\n",
      "        output_fname: ''\n",
      "        data_fields_map:\n",
      "          sequence: sequence\n",
      "          id: id\n",
      "      optim:\n",
      "        name: fused_adam\n",
      "        lr: 0.0004\n",
      "        weight_decay: 0.01\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        sched:\n",
      "          name: CosineAnnealing\n",
      "          warmup_steps: 2000\n",
      "          constant_steps: 50000\n",
      "          min_lr: 4.0e-05\n",
      "      dwnstr_task_validation:\n",
      "        enabled: true\n",
      "        dataset:\n",
      "          class: PerTokenPredictionCallback\n",
      "          task_type: token-level-classification\n",
      "          infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "          max_seq_length: 1024\n",
      "          emb_batch_size: 128\n",
      "          batch_size: 128\n",
      "          num_epochs: 10\n",
      "          shuffle: true\n",
      "          num_workers: 8\n",
      "          task_name: secondary_structure\n",
      "          dataset_path: /data/FLIP/secondary_structure\n",
      "          dataset:\n",
      "            train: x000\n",
      "            test: x000\n",
      "          sequence_column: sequence\n",
      "          target_column:\n",
      "          - 3state\n",
      "          - resolved\n",
      "          target_sizes:\n",
      "          - 3\n",
      "          - 2\n",
      "          mask_column:\n",
      "          - resolved\n",
      "          - null\n",
      "          random_seed: 1234\n",
      "          optim:\n",
      "            name: adam\n",
      "            lr: 0.0001\n",
      "            betas:\n",
      "            - 0.9\n",
      "            - 0.999\n",
      "            eps: 1.0e-08\n",
      "            weight_decay: 0.01\n",
      "            sched:\n",
      "              name: WarmupAnnealing\n",
      "              min_lr: 1.0e-05\n",
      "              last_epoch: -1\n",
      "              warmup_ratio: 0.01\n",
      "              max_steps: 1000\n",
      "      precision: 16\n",
      "      megatron_legacy: false\n",
      "      position_embedding_type: rope\n",
      "      embedding_use_attention_mask: true\n",
      "      embedding_token_dropout: true\n",
      "      mask_token_id: 32\n",
      "      attention_dropout: 0.0\n",
      "      use_esm_attention: true\n",
      "      normalize_attention_scores: false\n",
      "      esm_gelu: true\n",
      "      bias_gelu_fusion: false\n",
      "      use_pt_layernorm: false\n",
      "      use_pt_mlp_out: false\n",
      "      target: bionemo.model.protein.esm1nv.esm1nv_model.ESM2nvModel\n",
      "      nemo_version: 1.20.0\n",
      "      downstream_task:\n",
      "        restore_from_path: ${oc.env:BIONEMO_HOME}/models/protein/esm2nv/esm2nv_3B_converted.nemo\n",
      "        outputs:\n",
      "        - embeddings\n",
      "        - hiddens\n",
      "      global_batch_size: 32\n",
      "    target: bionemo.model.protein.esm1nv.esm1nv_model.ESM2nvModel\n",
      "    infer_target: bionemo.model.protein.esm1nv.infer.ESM1nvInference\n",
      "    formatters:\n",
      "      simple:\n",
      "        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'\n",
      "    handlers:\n",
      "      console:\n",
      "        class: logging.StreamHandler\n",
      "        formatter: simple\n",
      "        stream: ext://sys.stdout\n",
      "      file:\n",
      "        class: logging.FileHandler\n",
      "        formatter: simple\n",
      "        filename: /logs/inference.log\n",
      "    root:\n",
      "      level: INFO\n",
      "      handlers:\n",
      "      - console\n",
      "    disable_existing_loggers: false\n",
      "    \n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-08-23 15:48:19 tokenizer_utils:182] Getting HuggingFace AutoTokenizer with pretrained_model_name: facebook/esm2_t36_3B_UR50D\n",
      "[NeMo I 2024-08-23 15:48:19 megatron_base_model:264] Padded vocab_size: 128, original vocab_size: 33, dummy tokens: 95.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-23 15:48:19 base:92] Using custom ESM2 Embeddings instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:19 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 attention:87] Using custom ESM2 attention instead of the default NeMo version\n",
      "[NeMo W 2024-08-23 15:48:20 mlp:199] Using custom ESM2 GELU function instead of the default NeMo version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-23 15:48:28 nlp_overrides:401] Model ESM2nvModel was successfully restored from /workspace/bionemo/models/protein/esm2nv/esm2nv_3B_converted.nemo.\n",
      "Loaded a <class 'bionemo.model.protein.esm1nv.infer.ESM1nvInference'>\n"
     ]
    }
   ],
   "source": [
    "from bionemo.triton.utils import load_model_for_inference\n",
    "from bionemo.model.protein.esm1nv.infer import ESM1nvInference\n",
    "\n",
    "inferer = load_model_for_inference(cfg, interactive=True)\n",
    "\n",
    "print(f\"Loaded a {type(inferer)}\")\n",
    "assert isinstance(inferer, ESM1nvInference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5ffa4",
   "metadata": {},
   "source": [
    "### Turn off post_process\n",
    "\n",
    "After loading, we switch off post processing so that the inferer still returns hidden states like we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08965174",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferer.model.model.post_process = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296853f",
   "metadata": {},
   "source": [
    "### Sequence to Hidden States\n",
    "\n",
    "__`seq_to_hiddens`__ queries the model to fetch the encoder hiddens states for the input protein sequence. `pad_mask` is returned with `hidden_states` and contains padding information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b67b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.shape=torch.Size([2, 43, 2560])\n",
      "pad_masks.shape=torch.Size([2, 43])\n"
     ]
    }
   ],
   "source": [
    "hidden_states, pad_masks = inferer.seq_to_hiddens(seqs)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "assert tuple(hidden_states.shape) == (2, 43, 2560)  # ESM2nv has 2560 dimensions\n",
    "assert tuple(pad_masks.shape) == (2, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50280b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False],\n",
       "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check pad_masks\n",
    "pad_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1408be6",
   "metadata": {},
   "source": [
    "### Language model head\n",
    "\n",
    "Helpers for working with the ESM2nv BERT LM head.\n",
    "\n",
    "The tokenizer has classpath: `nemo.collections.common.tokenizers.huggingface.auto_tokenizer.AutoTokenizer`\n",
    "\n",
    "The source code for this should be findable on the BioNeMo Docker image at:\n",
    "```\n",
    "/usr/local/lib/python3.10/dist-packages/nemo/collections/common/tokenizers/huggingface/auto_tokenizer.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2ca899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertLMHead(\n",
       "  (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "  (layernorm): MixedFusedLayerNorm(torch.Size([2560]), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check we have the lm_head\n",
    "inferer.model.model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b60de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<cls>',\n",
       " '<pad>',\n",
       " '<eos>',\n",
       " '<unk>',\n",
       " 'L',\n",
       " 'A',\n",
       " 'G',\n",
       " 'V',\n",
       " 'S',\n",
       " 'E',\n",
       " 'R',\n",
       " 'T',\n",
       " 'I',\n",
       " 'D',\n",
       " 'P',\n",
       " 'K',\n",
       " 'Q',\n",
       " 'N',\n",
       " 'F',\n",
       " 'Y',\n",
       " 'M',\n",
       " 'H',\n",
       " 'W',\n",
       " 'C',\n",
       " 'X',\n",
       " 'B',\n",
       " 'U',\n",
       " 'Z',\n",
       " 'O',\n",
       " '.',\n",
       " '-',\n",
       " '<null_1>',\n",
       " '<mask>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check vocabulary\n",
    "inferer.tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3b526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_states_to_logits(hidden_states):\n",
    "    \"\"\"Take hidden_states from inferer.seq_to_hiddens(seqs) and apply the LM head.\n",
    "    \n",
    "    hidden_states.shape: <n_batch, n_max_seq_length_for_batch, 2560 hidden state dimensions>\n",
    "    \n",
    "    The logit shape has a fixed length of 128 tokens, however, ESM2nv only uses a vocabulary of 33.\n",
    "    So, we pare down to only the relevant vocabulary classes.\n",
    "    \"\"\"\n",
    "    with autocast(enabled=inferer.model.enable_autocast):\n",
    "        lm_out = inferer.model.model.lm_head(hidden_states, inferer.model.model.word_embeddings_weight())\n",
    "    logits = lm_out[:, :, :inferer.tokenizer.vocab_size]\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fed255",
   "metadata": {},
   "source": [
    "### Example 1a: Proba heatmap\n",
    "\n",
    "1. Get logits for a batch of seqs\n",
    "2. Pick a seq of interest\n",
    "3. Drop padding mask, which includes dropping SOS and EOS tokens too\n",
    "4. Apply softmax to convert logits to probabilities\n",
    "5. Make a fun heatmp viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163ee36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 33])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_logits = hidden_states_to_logits(hidden_states)\n",
    "\n",
    "i_seq_of_interest = 1\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]]\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d829b43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Position')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ms = ax.matshow(probas.T, cmap=\"viridis\")\n",
    "ax.set_yticks(range(len(inferer.tokenizer.vocab)))\n",
    "ax.set_yticklabels(inferer.tokenizer.vocab)\n",
    "fig.colorbar(ms)\n",
    "plt.ylabel(\"Token\")\n",
    "plt.xlabel(\"Position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02dc12",
   "metadata": {},
   "source": [
    "### Example 1b: Argmax\n",
    "\n",
    "1. Translate the logits/probas back into sequence space via argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b0abb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'                                       '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Argmax and compare prediction/reconstruction to true/input\n",
    "pred_idx_list = np.argmax(probas, axis=-1).tolist()\n",
    "true_idx_list = inferer.tokenizer.text_to_ids(seqs[i_seq_of_interest])\n",
    "\n",
    "pred_seq = inferer.tokenizer.ids_to_text(pred_idx_list).replace(\" \", \"\")\n",
    "true_seq = inferer.tokenizer.ids_to_text(true_idx_list).replace(\" \", \"\")\n",
    "\n",
    "display(pred_seq)\n",
    "display(\n",
    "    \"\".join(\n",
    "        [\" \" if a == b else \"|\" for a, b in zip(pred_seq, true_seq)]\n",
    "    )\n",
    ")\n",
    "display(true_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79dd1ca",
   "metadata": {},
   "source": [
    "I guess it does pretty perfect for Nvidia's little peptide examples! Easy when there's no masking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d783a12",
   "metadata": {},
   "source": [
    "### Example 1c: Compute log-proba of the sequence\n",
    "\n",
    "Given the reconstruction may not always be perfect, but we do know the exact input, we pluck out the posterior probas of the input tokens.\n",
    "\n",
    "1. Extract the input probas\n",
    "2. Log transform\n",
    "3. Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04140921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.arange(len(true_idx_list))\n",
    "cols = np.asarray(true_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2551a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.872187"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log posterior probability\n",
    "seq_log_proba = np.log(probas[rows, cols]).sum()\n",
    "seq_log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4aeaf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736497"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic mean probability\n",
    "np.mean(probas[rows, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad16036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64880687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geometric mean probability\n",
    "gmean(probas[rows, cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89828233",
   "metadata": {},
   "source": [
    "### Example 2: Mask some individual positions\n",
    "\n",
    "1. Make some masks\n",
    "2. Run the whole shebang to get probas of the masked token(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2196762",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_TOKEN = \"<mask>\"\n",
    "\n",
    "seqs = [\n",
    "    \"MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA\",  # original unmasked sequence\n",
    "    \"MIQ\" + MASK_TOKEN + \"QINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA\",\n",
    "    \"MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGT\" + MASK_TOKEN + \"LA\"\n",
    "]\n",
    "\n",
    "hidden_states, pad_masks = inferer.seq_to_hiddens(seqs)\n",
    "batch_logits = hidden_states_to_logits(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b67e514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9166275e-07, 1.5486411e-09, 3.4502878e-07, 1.5426036e-09,\n",
       "       7.3410109e-02, 4.6226468e-02, 3.6018379e-02, 3.9589096e-02,\n",
       "       6.5328188e-02, 8.7341182e-02, 6.3079573e-02, 5.6578685e-02,\n",
       "       6.7858428e-02, 4.7990602e-02, 4.4281568e-02, 1.2072847e-01,\n",
       "       5.4917075e-02, 7.1816191e-02, 3.7468623e-02, 3.0051233e-02,\n",
       "       1.9892376e-02, 2.3158453e-02, 7.0716641e-03, 7.1327849e-03,\n",
       "       5.9859522e-05, 1.7830074e-07, 5.7323231e-08, 1.3913223e-07,\n",
       "       1.0480195e-08, 9.9807584e-09, 9.5423260e-09, 9.2668211e-09,\n",
       "       1.5486411e-09], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_seq_of_interest = 1\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]]\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "probas[3]  # position of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba4a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('K', 15, 0.12072847),\n",
       " ('E', 9, 0.08734118),\n",
       " ('L', 4, 0.07341011),\n",
       " ('N', 17, 0.07181619),\n",
       " ('I', 12, 0.06785843),\n",
       " ('S', 8, 0.06532819),\n",
       " ('R', 10, 0.06307957),\n",
       " ('T', 11, 0.056578685),\n",
       " ('Q', 16, 0.054917075),\n",
       " ('D', 13, 0.0479906),\n",
       " ('A', 5, 0.046226468),\n",
       " ('P', 14, 0.04428157),\n",
       " ('V', 7, 0.039589096),\n",
       " ('F', 18, 0.037468623),\n",
       " ('G', 6, 0.03601838),\n",
       " ('Y', 19, 0.030051233),\n",
       " ('H', 21, 0.023158453),\n",
       " ('M', 20, 0.019892376),\n",
       " ('C', 23, 0.007132785),\n",
       " ('W', 22, 0.007071664),\n",
       " ('X', 24, 5.985952e-05),\n",
       " ('<eos>', 2, 3.4502878e-07),\n",
       " ('<cls>', 0, 1.9166275e-07),\n",
       " ('B', 25, 1.7830074e-07),\n",
       " ('Z', 27, 1.3913223e-07),\n",
       " ('U', 26, 5.732323e-08),\n",
       " ('O', 28, 1.0480195e-08),\n",
       " ('.', 29, 9.980758e-09),\n",
       " ('-', 30, 9.542326e-09),\n",
       " ('<null_1>', 31, 9.266821e-09),\n",
       " ('<pad>', 1, 1.5486411e-09),\n",
       " ('<mask>', 32, 1.5486411e-09),\n",
       " ('<unk>', 3, 1.5426036e-09)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sort = sorted(enumerate(probas[3]), key=lambda x: x[1], reverse=True)\n",
    "tmp = [(inferer.tokenizer.vocab[i], i, p) for i, p in tmp_sort]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f736b3",
   "metadata": {},
   "source": [
    "Hmm, ranks the original amino acid (S) at 6-th most probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a88fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0837189e-07, 1.6318511e-09, 6.6870302e-07, 1.6640366e-09,\n",
       "       5.7541151e-02, 5.4016158e-02, 2.8374764e-01, 3.8689706e-02,\n",
       "       5.4144058e-02, 4.3888409e-02, 5.2961290e-02, 3.1744529e-02,\n",
       "       4.1950762e-02, 4.8703197e-02, 2.4969662e-02, 6.0563575e-02,\n",
       "       2.7469456e-02, 6.0747180e-02, 3.2279260e-02, 2.5098775e-02,\n",
       "       1.2670239e-02, 2.8788622e-02, 6.4930846e-03, 1.3152466e-02,\n",
       "       3.7891296e-04, 4.4371561e-07, 2.6237984e-07, 2.0275142e-07,\n",
       "       1.4976942e-08, 8.8389509e-09, 1.0850882e-08, 1.1261116e-08,\n",
       "       1.6705494e-09], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_seq_of_interest = 2\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]]\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "probas[-3]  # position of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14173f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 6, 0.28374764),\n",
       " ('N', 17, 0.06074718),\n",
       " ('K', 15, 0.060563575),\n",
       " ('L', 4, 0.05754115),\n",
       " ('S', 8, 0.05414406),\n",
       " ('A', 5, 0.054016158),\n",
       " ('R', 10, 0.05296129),\n",
       " ('D', 13, 0.048703197),\n",
       " ('E', 9, 0.04388841),\n",
       " ('I', 12, 0.041950762),\n",
       " ('V', 7, 0.038689706),\n",
       " ('F', 18, 0.03227926),\n",
       " ('T', 11, 0.03174453),\n",
       " ('H', 21, 0.028788622),\n",
       " ('Q', 16, 0.027469456),\n",
       " ('Y', 19, 0.025098775),\n",
       " ('P', 14, 0.024969662),\n",
       " ('C', 23, 0.013152466),\n",
       " ('M', 20, 0.012670239),\n",
       " ('W', 22, 0.0064930846),\n",
       " ('X', 24, 0.00037891296),\n",
       " ('<eos>', 2, 6.68703e-07),\n",
       " ('B', 25, 4.437156e-07),\n",
       " ('U', 26, 2.6237984e-07),\n",
       " ('<cls>', 0, 2.0837189e-07),\n",
       " ('Z', 27, 2.0275142e-07),\n",
       " ('O', 28, 1.4976942e-08),\n",
       " ('<null_1>', 31, 1.1261116e-08),\n",
       " ('-', 30, 1.0850882e-08),\n",
       " ('.', 29, 8.838951e-09),\n",
       " ('<mask>', 32, 1.6705494e-09),\n",
       " ('<unk>', 3, 1.6640366e-09),\n",
       " ('<pad>', 1, 1.6318511e-09)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sort = sorted(enumerate(probas[-3]), key=lambda x: x[1], reverse=True)\n",
    "tmp = [(inferer.tokenizer.vocab[i], i, p) for i, p in tmp_sort]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdee98",
   "metadata": {},
   "source": [
    "Seems to like the original amino acid (G) here as most probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e49840",
   "metadata": {},
   "source": [
    "### Ignoring non-canonical amino acid tokens\n",
    "\n",
    "Often we only want our model to predict real amino acids, not the special tokens or unknowns. To do so, we can effectively mask tokens by adding negative infinity to the logits, forcing the softmax to yield zero probability for ignored tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90ac268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TO_TOKEN = inferer.tokenizer.vocab\n",
    "TOKEN_TO_IDX = {t: i for i, t in enumerate(IDX_TO_TOKEN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d27293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-inf, -inf, -inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_ignore = torch.zeros(len(IDX_TO_TOKEN), dtype=torch.float32)\n",
    "\n",
    "tokens_to_ignore = [\n",
    "   \"<cls>\", \"<eos>\", \"<null_1>\", \"<mask>\", \"<unk>\", \"<pad>\", \"-\", \".\", \"X\", \"B\", \"U\", \"Z\", \"O\"\n",
    "]\n",
    "\n",
    "for t in tokens_to_ignore:\n",
    "    mask_ignore[TOKEN_TO_IDX[t]] = -torch.inf\n",
    "    \n",
    "mask_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7446e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.05756307,\n",
       "       0.05403673, 0.2838557 , 0.03870444, 0.05416469, 0.04390512,\n",
       "       0.05298146, 0.03175662, 0.04196674, 0.04872175, 0.02497917,\n",
       "       0.06058664, 0.02747992, 0.06077031, 0.03229155, 0.02510833,\n",
       "       0.01267506, 0.02879959, 0.00649556, 0.01315747, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_seq_of_interest = 2\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]].detach().cpu()\n",
    "\n",
    "# Add the ignore mask\n",
    "probas = torch.softmax(logits + mask_ignore, dim=-1).detach().cpu().numpy()\n",
    "probas[-3]  # position of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "352ac14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 6, 0.2838557),\n",
       " ('N', 17, 0.06077031),\n",
       " ('K', 15, 0.06058664),\n",
       " ('L', 4, 0.057563066),\n",
       " ('S', 8, 0.054164685),\n",
       " ('A', 5, 0.05403673),\n",
       " ('R', 10, 0.05298146),\n",
       " ('D', 13, 0.04872175),\n",
       " ('E', 9, 0.04390512),\n",
       " ('I', 12, 0.04196674),\n",
       " ('V', 7, 0.038704436),\n",
       " ('F', 18, 0.032291554),\n",
       " ('T', 11, 0.031756617),\n",
       " ('H', 21, 0.028799586),\n",
       " ('Q', 16, 0.027479919),\n",
       " ('Y', 19, 0.025108332),\n",
       " ('P', 14, 0.02497917),\n",
       " ('C', 23, 0.013157475),\n",
       " ('M', 20, 0.012675064),\n",
       " ('W', 22, 0.0064955573),\n",
       " ('<cls>', 0, 0.0),\n",
       " ('<pad>', 1, 0.0),\n",
       " ('<eos>', 2, 0.0),\n",
       " ('<unk>', 3, 0.0),\n",
       " ('X', 24, 0.0),\n",
       " ('B', 25, 0.0),\n",
       " ('U', 26, 0.0),\n",
       " ('Z', 27, 0.0),\n",
       " ('O', 28, 0.0),\n",
       " ('.', 29, 0.0),\n",
       " ('-', 30, 0.0),\n",
       " ('<null_1>', 31, 0.0),\n",
       " ('<mask>', 32, 0.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sort = sorted(enumerate(probas[-3]), key=lambda x: x[1], reverse=True)\n",
    "tmp = [(inferer.tokenizer.vocab[i], i, p) for i, p in tmp_sort]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cdcc2f",
   "metadata": {},
   "source": [
    "The tokens we wanted to ignore all have exactly zero probability!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327318e",
   "metadata": {},
   "source": [
    "### Temperature\n",
    "\n",
    "Sometimes we want to increase or decrease the randomness of our probabilities for sampling. This can be done easily by dividing logits by a \"temperature\" scalar prior to applying the softmax function. As temperature increases, the probabilities approach uniform, equally probable. As the temperature decreases, the probabilities approach argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8da1d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 6, 0.7146954),\n",
       " ('N', 17, 0.03275734),\n",
       " ('K', 15, 0.03255963),\n",
       " ('L', 4, 0.029390948),\n",
       " ('S', 8, 0.026023047),\n",
       " ('A', 5, 0.025900245),\n",
       " ('R', 10, 0.02489852),\n",
       " ('D', 13, 0.021055784),\n",
       " ('E', 9, 0.017098425),\n",
       " ('I', 12, 0.015621983),\n",
       " ('V', 7, 0.0132876225),\n",
       " ('F', 18, 0.009249189),\n",
       " ('T', 11, 0.008945287),\n",
       " ('H', 21, 0.007356957),\n",
       " ('Q', 16, 0.0066981767),\n",
       " ('Y', 19, 0.0055919266),\n",
       " ('P', 14, 0.0055345427),\n",
       " ('C', 23, 0.0015355743),\n",
       " ('M', 20, 0.0014250366),\n",
       " ('W', 22, 0.00037424723),\n",
       " ('<cls>', 0, 0.0),\n",
       " ('<pad>', 1, 0.0),\n",
       " ('<eos>', 2, 0.0),\n",
       " ('<unk>', 3, 0.0),\n",
       " ('X', 24, 0.0),\n",
       " ('B', 25, 0.0),\n",
       " ('U', 26, 0.0),\n",
       " ('Z', 27, 0.0),\n",
       " ('O', 28, 0.0),\n",
       " ('.', 29, 0.0),\n",
       " ('-', 30, 0.0),\n",
       " ('<null_1>', 31, 0.0),\n",
       " ('<mask>', 32, 0.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the temperature as compare to above\n",
    "temperature = 0.5\n",
    "\n",
    "i_seq_of_interest = 2\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]].detach().cpu()\n",
    "logits /= temperature\n",
    "\n",
    "# Add the ignore mask\n",
    "probas = torch.softmax(logits + mask_ignore, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "tmp_sort = sorted(enumerate(probas[-3]), key=lambda x: x[1], reverse=True)\n",
    "tmp = [(inferer.tokenizer.vocab[i], i, p) for i, p in tmp_sort]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67f6c42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('G', 6, 0.12961921),\n",
       " ('N', 17, 0.05997445),\n",
       " ('K', 15, 0.05988375),\n",
       " ('L', 4, 0.058370378),\n",
       " ('S', 8, 0.05662115),\n",
       " ('A', 5, 0.05655423),\n",
       " ('R', 10, 0.05599929),\n",
       " ('D', 13, 0.053700954),\n",
       " ('E', 9, 0.050977454),\n",
       " ('I', 12, 0.04983944),\n",
       " ('V', 7, 0.047863115),\n",
       " ('F', 18, 0.04371848),\n",
       " ('T', 11, 0.04335485),\n",
       " ('H', 21, 0.041287035),\n",
       " ('Q', 16, 0.040330008),\n",
       " ('Y', 19, 0.03855045),\n",
       " ('P', 14, 0.038451172),\n",
       " ('C', 23, 0.027906595),\n",
       " ('M', 20, 0.027390225),\n",
       " ('W', 22, 0.019607795),\n",
       " ('<cls>', 0, 0.0),\n",
       " ('<pad>', 1, 0.0),\n",
       " ('<eos>', 2, 0.0),\n",
       " ('<unk>', 3, 0.0),\n",
       " ('X', 24, 0.0),\n",
       " ('B', 25, 0.0),\n",
       " ('U', 26, 0.0),\n",
       " ('Z', 27, 0.0),\n",
       " ('O', 28, 0.0),\n",
       " ('.', 29, 0.0),\n",
       " ('-', 30, 0.0),\n",
       " ('<null_1>', 31, 0.0),\n",
       " ('<mask>', 32, 0.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase the temperature as compare to above\n",
    "temperature = 2.0\n",
    "\n",
    "i_seq_of_interest = 2\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]].detach().cpu()\n",
    "logits /= temperature\n",
    "\n",
    "# Add the ignore mask\n",
    "probas = torch.softmax(logits + mask_ignore, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "tmp_sort = sorted(enumerate(probas[-3]), key=lambda x: x[1], reverse=True)\n",
    "tmp = [(inferer.tokenizer.vocab[i], i, p) for i, p in tmp_sort]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74732c0e",
   "metadata": {},
   "source": [
    "### Example 3: In-paint a bunch of masked tokens all in one go\n",
    "\n",
    "1. Mask a short contiguous part of a seq\n",
    "2. Unmask/in-paint all at once by taking the argmax\n",
    "3. Unmask/in-paint by sampling probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03090ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_TOKEN = \"<mask>\"\n",
    "\n",
    "before = \"M\"\n",
    "n_contig = 8\n",
    "contig = \"\".join([MASK_TOKEN] * n_contig)\n",
    "after = \"IRLDLADAILLSKAKKDLSFAEIADGTGLA\"\n",
    "\n",
    "seqs = [\n",
    "    \"MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA\",  # original unmasked sequence\n",
    "    before + contig + after\n",
    "]\n",
    "\n",
    "hidden_states, pad_masks = inferer.seq_to_hiddens(seqs)\n",
    "batch_logits = hidden_states_to_logits(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e58b8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use temperature and ignore mask\n",
    "temperature = 2.0\n",
    "\n",
    "i_seq_of_interest = 1\n",
    "logits = batch_logits[i_seq_of_interest]\n",
    "logits = logits[pad_masks[i_seq_of_interest]]\n",
    "logits /= temperature\n",
    "\n",
    "probas = torch.softmax(logits.cpu() + mask_ignore, dim=-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c265aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAKLLLLEAIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' ||||||||                              '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# argmax in-paint: only taken over the masked contig\n",
    "\n",
    "pred_idx_list = np.argmax(probas[len(before):len(before) + n_contig, :], axis=-1).tolist()\n",
    "in_paint = inferer.tokenizer.ids_to_text(pred_idx_list).replace(\" \", \"\")\n",
    "pred_seq = before + in_paint + after\n",
    "\n",
    "orig_seq = seqs[0]\n",
    "\n",
    "display(pred_seq)\n",
    "display(\n",
    "    \"\".join(\n",
    "        [\" \" if a == b else \"|\" for a, b in zip(pred_seq, orig_seq)]\n",
    "    )\n",
    ")\n",
    "display(orig_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b59cd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = []\n",
    "for p in probas[len(before):len(before) + n_contig, :]:\n",
    "    i = np.random.choice(np.arange(len(p)), p=p)\n",
    "    foo.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70b4a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MKKEAYDRTIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' |||||| |                              '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probability sample in-paint: only taken over the masked contig\n",
    "\n",
    "np.random.seed(88888)\n",
    "\n",
    "pred_idx_list = []\n",
    "for p in probas[len(before):len(before) + n_contig, :]:\n",
    "    i = np.random.choice(np.arange(len(p)), p=p)\n",
    "    pred_idx_list.append(i)\n",
    "\n",
    "in_paint = inferer.tokenizer.ids_to_text(pred_idx_list).replace(\" \", \"\")\n",
    "pred_seq = before + in_paint + after\n",
    "\n",
    "orig_seq = seqs[0]\n",
    "\n",
    "display(pred_seq)\n",
    "display(\n",
    "    \"\".join(\n",
    "        [\" \" if a == b else \"|\" for a, b in zip(pred_seq, orig_seq)]\n",
    "    )\n",
    ")\n",
    "display(orig_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef2c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
