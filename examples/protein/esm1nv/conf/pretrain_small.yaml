defaults:
  - base_config
model:
  tokenizer:
    library: 'sentencepiece'
    type: null
    model: /model/protein/esm1nv/vocab/protein_sequence_sentencepiece.model
    vocab_file: /model/vocab/protein_sequence.vocab
  data:
    dataset_path: /data/uniref2022_05 # parent directory for data, contains train / val / test folders. Needs to be writeable for index creation.
    dataset: # inclusive range of data files to load x[000..049] or can a single file, e.g. x000
      train: x[000..049]
      test: x[000..049]
      val: x[000..049]
    micro_batch_size: ${model.micro_batch_size}
    num_workers: 10
    data_col: 3 # 0-based
    data_sep: ',' # string to split text into columns
    header_lines: 1 # skip first N header lines
    data_prefix: "" # must be "" or null
    modify_percent: 0.1 # Percentage of characters in a protein sequence to modify. (Modification means replacing with another amino acid or with a mask token)
    perturb_percent: 0.5 # Of the modify_percent, what percentage of characters are to be replaced with another amino acid.
    seed: ${model.seed} # Random seed
    max_seq_length: ${model.seq_length} # Maximum input sequence length. Longer sequences are truncated
