{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot prediction of BRCA1 variant effects with Evo 2\n",
    "\n",
    "*Note - this notebook is a reproduction of The Arc Institute’s same-titled notebook [here](https://github.com/ArcInstitute/evo2/blob/main/notebooks/brca1/brca1_zero_shot_vep.ipynb), using the BioNeMo 2 implementation of Evo2.*\n",
    "\n",
    "The human *BRCA1* gene encodes for a protein that repairs damaged DNA ([Moynahan et al., 1999](https://www.cell.com/molecular-cell/fulltext/S1097-2765%2800%2980202-6)). Certain variants of this gene have been associated with an increased risk of breast and ovarian cancers ([Miki et al., 1994](https://www.science.org/doi/10.1126/science.7545954?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)). Using Evo 2, we can predict whether a particular single nucleotide variant (SNV) of the *BRCA1* gene is likely to be harmful to the protein's function, and thus potentially increase the risk of cancer for the patient with the genetic variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.85)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a dataset from [Findlay et al. (2018)](https://www.nature.com/articles/s41586-018-0461-z), which contains experimentally measured function scores of 3,893 *BRCA1* SNVs. These function scores reflect the extent by which the genetic variant has disrupted the protein's function, with lower scores indicating greater disruption. In this dataset, the SNVs are classified into three categories based on their function scores: `LOF` (loss-of-function), `INT` (intermediate), and `FUNC` (functional). We start by reading in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data if not present\n",
    "if not os.path.exists('brca1'):\n",
    "    os.makedirs('brca1')\n",
    "\n",
    "commit_hash = \"3819474bee6c24938016614411f1fa025e542bbe\"\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/{commit_hash}/notebooks/brca1/41586_2018_461_MOESM3_ESM.xlsx -O brca1/41586_2018_461_MOESM3_ESM.xlsx\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/{commit_hash}/notebooks/brca1/GRCh37.p13_chr17.fna.gz -O brca1/GRCh37.p13_chr17.fna.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then group the `FUNC` and `INT` classes of SNVs together into a single category (`FUNC/INT`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.372611</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.108254</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.277963</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.280973</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.973683</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.373489</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>41276132</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.207552</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class\n",
       "0     17  41276135   T   G -0.372611  FUNC/INT\n",
       "1     17  41276135   T   C -0.045313  FUNC/INT\n",
       "2     17  41276135   T   A -0.108254  FUNC/INT\n",
       "3     17  41276134   T   G -0.277963  FUNC/INT\n",
       "4     17  41276134   T   C -0.388414  FUNC/INT\n",
       "5     17  41276134   T   A -0.280973  FUNC/INT\n",
       "6     17  41276133   C   T -0.973683  FUNC/INT\n",
       "7     17  41276133   C   G -0.373489  FUNC/INT\n",
       "8     17  41276133   C   A  0.006314  FUNC/INT\n",
       "9     17  41276132   A   T -0.207552  FUNC/INT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca1_df = pd.read_excel(\n",
    "    os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx'),\n",
    "    header=2,\n",
    ")\n",
    "brca1_df = brca1_df[[\n",
    "    'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',\n",
    "]]\n",
    "\n",
    "# Rename columns\n",
    "brca1_df.rename(columns={\n",
    "    'chromosome': 'chrom',\n",
    "    'position (hg19)': 'pos',\n",
    "    'reference': 'ref',\n",
    "    'alt': 'alt',\n",
    "    'function.score.mean': 'score',\n",
    "    'func.class': 'class',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert to two-class system\n",
    "brca1_df['class'] = brca1_df['class'].replace(['FUNC', 'INT'], 'FUNC/INT')\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a function to parse the reference and variant sequences of a 8,192-bp window around the genomic position of each SNV, using the reference sequence of human chromosome 17 where *BRCA1* is located.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 8192\n",
    "\n",
    "# Read the reference genome sequence of chromosome 17\n",
    "with gzip.open(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz'), \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_chr17 = str(record.seq)\n",
    "        break\n",
    "\n",
    "def parse_sequences(pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Parse reference and variant sequences from the reference genome sequence.\n",
    "    \"\"\"\n",
    "    p = pos - 1 # Convert to 0-indexed position\n",
    "    full_seq = seq_chr17\n",
    "\n",
    "    ref_seq_start = max(0, p - WINDOW_SIZE//2)\n",
    "    ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2)\n",
    "    ref_seq = seq_chr17[ref_seq_start:ref_seq_end]\n",
    "    snv_pos_in_ref = min(WINDOW_SIZE//2, p)\n",
    "    var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1:]\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(var_seq) == len(ref_seq)\n",
    "    assert ref_seq[snv_pos_in_ref] == ref\n",
    "    assert var_seq[snv_pos_in_ref] == alt\n",
    "\n",
    "    return ref_seq, var_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things run faster, we'll just look at a balanced sample of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disable_sample = False\n",
    "SAMPLE_FRAC = 0.05\n",
    "balanced_sample = True\n",
    "\n",
    "random_state = 42\n",
    "if not disable_sample:\n",
    "    if balanced_sample:\n",
    "        # Get the number of rows in the dataframe\n",
    "        num_rows_minor_class = math.ceil(len(brca1_df[brca1_df['class'] == 'LOF']) * SAMPLE_FRAC)\n",
    "        brca1_df = pd.concat([\n",
    "            brca1_df[brca1_df['class'] == 'LOF'].sample(n=num_rows_minor_class, random_state=random_state),\n",
    "            brca1_df[brca1_df['class'] == 'FUNC/INT'].sample(n=num_rows_minor_class, random_state=random_state)\n",
    "        ]).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "    else:\n",
    "        # Calculate the number of rows to sample\n",
    "        num_rows_to_sample = int(len(brca1_df) * SAMPLE_FRAC)\n",
    "        brca1_df = brca1_df.sample(frac=SAMPLE_FRAC, random_state=random_state).reset_index(drop=True)\n",
    "brca1_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll write these to local `.fasta` files so we can use them for prediction below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique reference sequences: 79\n",
      "Total unique variant sequences: 84\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"brca1_fasta_files\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save reference and variant sequences to FASTA\n",
    "ref_fasta_path = output_dir / \"brca1_reference_sequences.fasta\"\n",
    "var_fasta_path = output_dir / \"brca1_variant_sequences.fasta\"\n",
    "\n",
    "# Track unique sequences\n",
    "ref_sequences = set()\n",
    "var_sequences = set()\n",
    "ref_seq_to_name = {}\n",
    "# Store unique sequences with metadata for writing\n",
    "ref_entries = []\n",
    "var_entries = []\n",
    "ref_names = []\n",
    "var_names = []\n",
    "# Collect unique reference and variant sequences\n",
    "for idx, row in brca1_df.iterrows():\n",
    "    ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "    # Add to sets to ensure uniqueness\n",
    "    if ref_seq not in ref_sequences:\n",
    "        ref_sequences.add(ref_seq)\n",
    "        ref_name = f\"BRCA1_ref_pos_{row['pos']}_{row['ref']}_class_{row['class']}\"\n",
    "\n",
    "        ref_entries.append(\n",
    "            f\">{ref_name}\\n{ref_seq}\\n\"\n",
    "        )\n",
    "        ref_names.append(ref_name)\n",
    "        ref_seq_to_name[ref_seq] = ref_name\n",
    "    else:\n",
    "        ref_name = ref_seq_to_name[ref_seq]\n",
    "        ref_names.append(ref_name)\n",
    "    if var_seq not in var_sequences:\n",
    "        var_sequences.add(var_seq)\n",
    "        var_name = f\"BRCA1_var_pos_{row['pos']}_{row['ref']}to{row['alt']}_class_{row['class']}\"\n",
    "\n",
    "        var_entries.append(\n",
    "            f\">{var_name}\\n{var_seq}\\n\"\n",
    "        )\n",
    "        var_names.append(var_name)\n",
    "    else:\n",
    "        assert False, \"Duplicate variant sequence\"\n",
    "\n",
    "# Write unique sequences to FASTA files\n",
    "with open(ref_fasta_path, \"w\") as f:\n",
    "    f.writelines(ref_entries)\n",
    "\n",
    "with open(var_fasta_path, \"w\") as f:\n",
    "    f.writelines(var_entries)\n",
    "\n",
    "\n",
    "brca1_df['ref_fasta_name'] = ref_names\n",
    "brca1_df['var_fasta_name'] = var_names\n",
    "\n",
    "# Print counts\n",
    "print(f\"Total unique reference sequences: {len(ref_sequences)}\")\n",
    "print(f\"Total unique variant sequences: {len(var_sequences)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, we load Evo 2 1B model, loading the Evo 2 weights from hugging face.\n",
    "\n",
    "*Note - for better performance, load the 7b model by replacing all occurrences of `1b` below with `7b`.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory is not empty. Skipping command.\n"
     ]
    }
   ],
   "source": [
    "# Define checkpoint path\n",
    "checkpoint_path = Path(\"nemo2_evo2_1b_8k\")\n",
    "\n",
    "# Check if the directory does not exist or is empty\n",
    "if not checkpoint_path.exists() or not any(checkpoint_path.iterdir()):\n",
    "    !evo2_convert_to_nemo2 --model-path hf://arcinstitute/savanna_evo2_1b_base --model-size 1b --output-dir nemo2_evo2_1b_8k\n",
    "else:\n",
    "    print(\"Checkpoint directory is not empty. Skipping command.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we score the likelihoods of the reference and variant sequences of each SNV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories for prediction results\n",
    "predict_ref_dir = output_dir / \"reference_predictions\"\n",
    "predict_var_dir = output_dir / \"variant_predictions\"\n",
    "predict_ref_dir.mkdir(parents=True, exist_ok=True)\n",
    "predict_var_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Update predict commands to run on the full dataset\n",
    "predict_ref_command = (\n",
    "    f\"predict_evo2 --fasta {ref_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_ref_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs\"\n",
    ")\n",
    "\n",
    "predict_var_command = (\n",
    "    f\"predict_evo2 --fasta {var_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_var_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-03 23:36:30 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-03-03 23:36:31 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Experiments will be logged at /tmp/tmpsn4mexa6/default\n",
      "[NeMo W 2025-03-03 23:36:31 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpsn4mexa6\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:36:31 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-03-03 23:36:31 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-03-03 23:36:32 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:36:32 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-03-03 23:36:32 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-03-03 23:36:32 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-03-03 23:36:32 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-03-03 23:36:32 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "[NeMo I 2025-03-03 23:36:32 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-03 23:36:32 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x769f8ed2e7e0> dist-ckpt load strategy.\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-03-03 23:36:33 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1741044992.504s : Time spent in load_checkpoint: 1.046s\n",
      "[NeMo I 2025-03-03 23:36:33 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-03 23:36:33 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    }
   ],
   "source": [
    "!{predict_ref_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict variant seqs (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-03 23:37:15 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-03-03 23:37:17 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Experiments will be logged at /tmp/tmpcu9581ff/default\n",
      "[NeMo W 2025-03-03 23:37:17 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpcu9581ff\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-03-03 23:37:17 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-03 23:37:17 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-03-03 23:37:17 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-03-03 23:37:17 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-03-03 23:37:17 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-03 23:37:17 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7766d25acb60> dist-ckpt load strategy.\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-03-03 23:37:18 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1741045037.679s : Time spent in load_checkpoint: 1.103s\n",
      "[NeMo I 2025-03-03 23:37:18 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-03 23:37:18 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    }
   ],
   "source": [
    "!{predict_var_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the change in likelihoods for each variant relative to the likelihood of their respective wild-type sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the prediction files and sequence id maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load prediction files\n",
    "ref_pred_files = glob.glob(os.path.join(predict_ref_dir, \"predictions__rank_*.pt\"))\n",
    "var_pred_files = glob.glob(os.path.join(predict_var_dir, \"predictions__rank_*.pt\"))\n",
    "\n",
    "# Load sequence ID maps (maps sequence ID -> prediction index)\n",
    "with open(os.path.join(predict_ref_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    ref_seq_idx_map = json.load(f)\n",
    "with open(os.path.join(predict_var_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    var_seq_idx_map = json.load(f)\n",
    "\n",
    "# Load predictions\n",
    "ref_preds = torch.load(ref_pred_files[0])\n",
    "var_preds = torch.load(var_pred_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, calculate the delta score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "      <th>ref_fasta_name</th>\n",
       "      <th>var_fasta_name</th>\n",
       "      <th>ref_log_probs</th>\n",
       "      <th>var_log_probs</th>\n",
       "      <th>evo2_delta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41199726</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>0.159762</td>\n",
       "      <td>FUNC/INT</td>\n",
       "      <td>BRCA1_ref_pos_41199726_T_class_FUNC/INT</td>\n",
       "      <td>BRCA1_var_pos_41199726_TtoC_class_FUNC/INT</td>\n",
       "      <td>-1.048409</td>\n",
       "      <td>-1.048462</td>\n",
       "      <td>-0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41209074</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.065569</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41209074_T_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41209074_TtoA_class_LOF</td>\n",
       "      <td>-0.826655</td>\n",
       "      <td>-0.826915</td>\n",
       "      <td>-0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41256913</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.847753</td>\n",
       "      <td>FUNC/INT</td>\n",
       "      <td>BRCA1_ref_pos_41256913_A_class_FUNC/INT</td>\n",
       "      <td>BRCA1_var_pos_41256913_AtoC_class_FUNC/INT</td>\n",
       "      <td>-0.864035</td>\n",
       "      <td>-0.864014</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41219631</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.053739</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41219631_T_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41219631_TtoA_class_LOF</td>\n",
       "      <td>-1.091372</td>\n",
       "      <td>-1.091227</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41215965</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.671525</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41215965_G_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41215965_GtoA_class_LOF</td>\n",
       "      <td>-0.930776</td>\n",
       "      <td>-0.930750</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class  \\\n",
       "0     17  41199726   T   C  0.159762  FUNC/INT   \n",
       "1     17  41209074   T   A -2.065569       LOF   \n",
       "2     17  41256913   A   C -0.847753  FUNC/INT   \n",
       "3     17  41219631   T   A -2.053739       LOF   \n",
       "4     17  41215965   G   A -1.671525       LOF   \n",
       "\n",
       "                            ref_fasta_name  \\\n",
       "0  BRCA1_ref_pos_41199726_T_class_FUNC/INT   \n",
       "1       BRCA1_ref_pos_41209074_T_class_LOF   \n",
       "2  BRCA1_ref_pos_41256913_A_class_FUNC/INT   \n",
       "3       BRCA1_ref_pos_41219631_T_class_LOF   \n",
       "4       BRCA1_ref_pos_41215965_G_class_LOF   \n",
       "\n",
       "                               var_fasta_name  ref_log_probs  var_log_probs  \\\n",
       "0  BRCA1_var_pos_41199726_TtoC_class_FUNC/INT      -1.048409      -1.048462   \n",
       "1       BRCA1_var_pos_41209074_TtoA_class_LOF      -0.826655      -0.826915   \n",
       "2  BRCA1_var_pos_41256913_AtoC_class_FUNC/INT      -0.864035      -0.864014   \n",
       "3       BRCA1_var_pos_41219631_TtoA_class_LOF      -1.091372      -1.091227   \n",
       "4       BRCA1_var_pos_41215965_GtoA_class_LOF      -0.930776      -0.930750   \n",
       "\n",
       "   evo2_delta_score  \n",
       "0         -0.000054  \n",
       "1         -0.000260  \n",
       "2          0.000021  \n",
       "3          0.000145  \n",
       "4          0.000026  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, calculate change in likelihoods\n",
    "ref_log_probs = []\n",
    "var_log_probs = []\n",
    "for _, row in brca1_df.iterrows():\n",
    "    ref_name = row['ref_fasta_name']\n",
    "    var_name = row['var_fasta_name']\n",
    "    ref_log_probs.append(ref_preds['log_probs_seqs'][ref_seq_idx_map[ref_name]].item())\n",
    "    var_log_probs.append(var_preds['log_probs_seqs'][var_seq_idx_map[var_name]].item())\n",
    "brca1_df['ref_log_probs'] = ref_log_probs\n",
    "brca1_df['var_log_probs'] = var_log_probs\n",
    "# ideally probability of a broken variant is lower than a good one. So a bad var - good ref is negative.\n",
    "brca1_df['evo2_delta_score'] = brca1_df['var_log_probs'] - brca1_df['ref_log_probs']\n",
    "brca1_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This delta likelihood should be predictive of how disruptive the SNV is to the protein's function: the lower the delta, the more likely that the SNV is disruptive. We can show this by comparing the distributions of delta likelihoods for the two classes of SNVs (functional/intermediate vs loss-of-function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "# Plot stripplot of distributions\n",
    "p = sns.stripplot(\n",
    "    data=brca1_df,\n",
    "    x='evo2_delta_score',\n",
    "    y='class',\n",
    "    hue='class',\n",
    "    order=['FUNC/INT', 'LOF'],\n",
    "    palette=['#777777', 'C3'],\n",
    "    size=2,\n",
    "    jitter=0.3,\n",
    ")\n",
    "\n",
    "# Mark medians from each distribution\n",
    "sns.boxplot(showmeans=True,\n",
    "            meanline=True,\n",
    "            meanprops={'visible': False},\n",
    "            medianprops={'color': 'k', 'ls': '-', 'lw': 2},\n",
    "            whiskerprops={'visible': False},\n",
    "            zorder=10,\n",
    "            x=\"evo2_delta_score\",\n",
    "            y=\"class\",\n",
    "            data=brca1_df,\n",
    "            showfliers=False,\n",
    "            showbox=False,\n",
    "            showcaps=False,\n",
    "            ax=p)\n",
    "plt.xlabel('Delta likelihood score, Evo 2')\n",
    "plt.ylabel('BRCA1 SNV class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the area under the receiver operating characteristic curve (AUROC) of this zero-shot prediction method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot prediction AUROC: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUROC of zero-shot predictions\n",
    "#  class 1 is LOF which is the bad thing. That means we expect this to be more negative.\n",
    "y_true = (brca1_df['class'] == 'LOF')\n",
    "auroc = roc_auc_score(y_true, -brca1_df['evo2_delta_score'])\n",
    "print(f'Zero-shot prediction AUROC: {auroc:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
