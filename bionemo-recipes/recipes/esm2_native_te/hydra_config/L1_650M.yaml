defaults:
  - defaults
  - _self_

# Training config
model_tag: nvidia/esm2_t33_650M_UR50D
num_train_steps: 200

dataset:
  micro_batch_size: 4

# WandB config
wandb_init_args:
  name: "esm2_t33_650M_UR50D"
  project: "bionemo-recipes"
  mode: "online"

checkpoint:
  ckpt_dir: "checkpoints/esm2_t33_650M_UR50D_sanity"

# Note: The layers are going to come in 1 indexed and we convert them to be 0 indexed at runtime.
fp8_layers:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 27
  - 28
  - 29
  - 30
  - 31
  - 32
  - 33

fp4_layers:
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  - 16
  - 17
  - 18
  - 19
  - 20
  - 21
  - 22
  - 23
  - 24
  - 25
  - 26

use_fp32_optimizer_weights: true