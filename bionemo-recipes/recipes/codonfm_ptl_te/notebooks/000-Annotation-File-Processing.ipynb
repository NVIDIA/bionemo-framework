{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92fb3d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENCODE version: v47\n",
      "Reference directory: /data/for_paper/data/reference\n"
     ]
    }
   ],
   "source": [
    "# Annotation File Processing\n",
    "# This notebook processes GENCODE GTF annotation files to extract protein-coding\n",
    "# transcript information and exports it in a tabular format suitable for downstream analysis.\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "REFERENCE_DIR = \"/data/for_paper/data/reference\"\n",
    "GENCODE_VERSION = \"v47\"\n",
    "\n",
    "# Input: GENCODE GTF files (downloaded from https://www.gencodegenes.org/)\n",
    "GTF_FILES = {\n",
    "    \"hg38\": f\"{REFERENCE_DIR}/gencode.{GENCODE_VERSION}.basic.annotation.gtf.gz\",\n",
    "    \"hg19\": f\"{REFERENCE_DIR}/gencode.{GENCODE_VERSION}lift37.basic.annotation.gtf.gz\",\n",
    "}\n",
    "\n",
    "# Output: Processed annotation TSV files\n",
    "OUTPUT_FILES = {\n",
    "    \"hg38\": f\"{REFERENCE_DIR}/gencode.{GENCODE_VERSION}.basic.annotation.processed.tsv\",\n",
    "    \"hg19\": f\"{REFERENCE_DIR}/gencode.{GENCODE_VERSION}lift37.basic.annotation.processed.tsv\",\n",
    "}\n",
    "\n",
    "print(f\"GENCODE version: {GENCODE_VERSION}\")\n",
    "print(f\"Reference directory: {REFERENCE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "562e1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to validate and adjust CDS (coding sequence) boundaries\n",
    "# These functions ensure that the exon coordinates properly include the stop codon (3 bp)\n",
    "\n",
    "def check_start_alignment(row):\n",
    "    \"\"\"\n",
    "    Validates that CDS start aligns with exon start and adjusts for stop codon on minus strand.\n",
    "    For minus strand genes, the stop codon is at the 3' end (lowest genomic position), so we subtract 3 bp.\n",
    "    \"\"\"\n",
    "    cds_start = row['cds_start']\n",
    "    exon_starts = list(map(int, row['exon_starts'].strip(',').split(',')))\n",
    "    if row['strand'] == '-':\n",
    "        # Extend first exon by 3 bp to include stop codon (on minus strand)\n",
    "        exon_starts[0] -= 3\n",
    "    assert cds_start == exon_starts[0], f\"{cds_start} != {exon_starts[0]} {row['transcript_id']}\"\n",
    "\n",
    "    exon_starts = ','.join(map(str, exon_starts)) + ','\n",
    "    return exon_starts\n",
    "\n",
    "def check_end_alignment(row):\n",
    "    \"\"\"\n",
    "    Validates that CDS end aligns with exon end and adjusts for stop codon on plus strand.\n",
    "    For plus strand genes, the stop codon is at the 3' end (highest genomic position), so we add 3 bp.\n",
    "    \"\"\"\n",
    "    cds_end = row['cds_end']\n",
    "    exon_ends = list(map(int, row['exon_ends'].strip(',').split(',')))\n",
    "    if row['strand'] == '+':\n",
    "        # Extend last exon by 3 bp to include stop codon (on plus strand)\n",
    "        exon_ends[-1] += 3\n",
    "    assert cds_end == exon_ends[-1], f\"{cds_end} != {exon_ends[-1]} {row['transcript_id']}\"\n",
    "\n",
    "    exon_ends = ','.join(map(str, exon_ends)) + ','\n",
    "    return exon_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9b630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gtf_file(gtf_file, output_file):\n",
    "    \"\"\"\n",
    "    Process a GENCODE GTF file and extract protein-coding transcript annotations.\n",
    "    \n",
    "    This function:\n",
    "    1. Parses the GTF file and extracts relevant attributes\n",
    "    2. Filters for protein-coding genes only\n",
    "    3. Aggregates exon/CDS coordinates per transcript\n",
    "    4. Adjusts coordinates to include stop codons\n",
    "    5. Outputs a tab-separated file with transcript annotations\n",
    "    \n",
    "    Args:\n",
    "        gtf_file: Path to input GENCODE GTF file (can be gzipped)\n",
    "        output_file: Path for output TSV file\n",
    "    \"\"\"\n",
    "    # Read GTF file (standard 9-column format)\n",
    "    gtf = pl.read_csv(gtf_file, comment_prefix='#', separator='\\t', has_header=False)\n",
    "    gtf.columns = ['chrom', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute']\n",
    "    \n",
    "    # Parse the attribute column (column 9) to extract key-value pairs\n",
    "    # GTF attributes are semicolon-separated with format: key \"value\"\n",
    "    gtf = gtf.with_columns([\n",
    "        pl.col('attribute').str.extract('gene_id \"(.*?)\"', 1).alias('gene_id'),\n",
    "        pl.col('attribute').str.extract('transcript_id \"(.*?)\"', 1).alias('transcript_id'),\n",
    "        pl.col('attribute').str.extract('gene_name \"(.*?)\"', 1).alias('gene_name'),\n",
    "        pl.col('attribute').str.extract('gene_type \"(.*?)\"', 1).alias('gene_type'),\n",
    "        pl.col('attribute').str.extract('transcript_type \"(.*?)\"', 1).alias('transcript_type'),\n",
    "        pl.col('attribute').str.extract('exon_number (.*?);', 1).alias('exon_number')\n",
    "    ])\n",
    "    \n",
    "    # Flag canonical transcripts (Ensembl canonical and MANE Select)\n",
    "    gtf = gtf.with_columns(pl.col('attribute').str.contains('Ensembl_canonical').alias('is_canonical'))\n",
    "    gtf = gtf.with_columns(pl.col('attribute').str.contains('MANE_Select').alias('is_mane_select'))\n",
    "    \n",
    "    # Filter to protein-coding genes only, exclude gene-level features\n",
    "    protein_coding_gtf = gtf.filter((pl.col('gene_type') == 'protein_coding') & (pl.col('feature') != 'gene'))\n",
    "    # Filter to protein-coding transcripts only\n",
    "    protein_coding_gtf = protein_coding_gtf.filter(pl.col('transcript_type') == 'protein_coding')\n",
    "    \n",
    "    # Convert from 1-based (GTF) to 0-based coordinates (BED-like format)\n",
    "    protein_coding_gtf = protein_coding_gtf.with_columns(pl.col('start') - 1)\n",
    "    \n",
    "    # Aggregate CDS exon coordinates per transcript\n",
    "    # Creates comma-separated lists of exon start/end positions (sorted by genomic position)\n",
    "    exon_starts = protein_coding_gtf.filter(pl.col('feature') == 'CDS').group_by('transcript_id').agg(\n",
    "        (pl.col('start').sort().cast(str).str.join(',') + ',').alias('exon_starts'),\n",
    "        (pl.col('end').sort().cast(str).str.join(',') + ',').alias('exon_ends'),\n",
    "        pl.col('exon_number').max().alias('exon_count')\n",
    "    )\n",
    "    \n",
    "    # Calculate CDS boundaries with stop codon adjustment\n",
    "    # GENCODE GTF excludes stop codon from CDS, but we want to include it\n",
    "    # For + strand: stop codon is after the last CDS position (add 3 to max end)\n",
    "    # For - strand: stop codon is before the first CDS position (subtract 3 from min start)\n",
    "    # Note: Using min()/max() instead of first()/last() to avoid dependency on row order\n",
    "    cds_starts = protein_coding_gtf.filter(pl.col('feature') == 'CDS').group_by('transcript_id').agg(\n",
    "        pl.when(pl.col('strand').first() == '-')\n",
    "        .then(pl.col('start').min() - 3)  # Include stop codon at 3' end (lowest genomic position)\n",
    "        .otherwise(pl.col('start').min())  # 5' end, no adjustment needed\n",
    "        .alias('cds_start'),\n",
    "        pl.when(pl.col('strand').first() == '-')\n",
    "        .then(pl.col('end').max())  # 5' end (highest genomic position), no adjustment\n",
    "        .otherwise(pl.col('end').max() + 3)  # Include stop codon at 3' end\n",
    "        .alias('cds_end'),\n",
    "    )\n",
    "    \n",
    "    # Get transcript-level metadata (gene info, coordinates, canonical status)\n",
    "    tx_starts = protein_coding_gtf.filter(pl.col('feature') == 'transcript').group_by('transcript_id').agg(\n",
    "        pl.col('gene_id').first().alias('gene_id'),\n",
    "        pl.col('gene_name').first().alias('gene_name'),\n",
    "        pl.col('chrom').first().alias('chrom'),\n",
    "        pl.col('strand').first().alias('strand'),\n",
    "        pl.col('start').min().alias('tx_start'),\n",
    "        pl.col('end').max().alias('tx_end'),\n",
    "        pl.col('transcript_type').first().alias('transcript_type'),\n",
    "        pl.col('is_canonical').first().alias('is_canonical'),\n",
    "        pl.col('is_mane_select').first().alias('is_mane_select'),\n",
    "    )\n",
    "    \n",
    "    # Join all transcript information together\n",
    "    joined_df = tx_starts.join(cds_starts, on='transcript_id', how='inner')\\\n",
    "                        .join(exon_starts, on='transcript_id', how='inner')\n",
    "    \n",
    "    # Validate and adjust exon coordinates to include stop codon\n",
    "    joined_df = joined_df.with_columns(\n",
    "        pl.struct(['cds_start', 'exon_starts', 'strand', 'transcript_id']).map_elements(check_start_alignment, return_dtype=pl.Utf8).alias('exon_starts'),\n",
    "        pl.struct(['cds_end', 'exon_ends', 'strand', 'transcript_id']).map_elements(check_end_alignment, return_dtype=pl.Utf8).alias('exon_ends')\n",
    "    )\n",
    "    \n",
    "    # Sort by chromosome and position, then select and rename columns for output\n",
    "    joined_df = joined_df.sort(['chrom', 'tx_start'])\n",
    "    joined_df = joined_df.select([\n",
    "        'gene_id',\n",
    "        'transcript_id',\n",
    "        'chrom',\n",
    "        'strand',\n",
    "        'tx_start',\n",
    "        'tx_end', \n",
    "        'cds_start',\n",
    "        'cds_end',\n",
    "        'exon_count',\n",
    "        'exon_starts',\n",
    "        'exon_ends',\n",
    "        'gene_name',\n",
    "        'transcript_type',\n",
    "        'is_canonical',\n",
    "        'is_mane_select'\n",
    "    ]).rename({\n",
    "        'transcript_id': 'name',        # Transcript ID becomes the 'name' field\n",
    "        'tx_start': 'txStart',          # Transcript start position\n",
    "        'tx_end': 'txEnd',              # Transcript end position\n",
    "        'cds_start': 'cdsStart',        # CDS start (including stop codon adjustment)\n",
    "        'cds_end': 'cdsEnd',            # CDS end (including stop codon adjustment)\n",
    "        'exon_starts': 'exonStarts',     # Comma-separated exon start positions\n",
    "        'exon_ends': 'exonEnds'          # Comma-separated exon end positions\n",
    "    })\n",
    "\n",
    "    # Write output as tab-separated file\n",
    "    joined_df.write_csv(output_file, separator='\\t')\n",
    "\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62147898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hg38: /data/for_paper/data/reference/gencode.v47.basic.annotation.gtf.gz\n",
      "Output saved to: /data/for_paper/data/reference/gencode.v47.basic.annotation.processed.tsv\n",
      "\n",
      "Processing hg19: /data/for_paper/data/reference/gencode.v47lift37.basic.annotation.gtf.gz\n",
      "Output saved to: /data/for_paper/data/reference/gencode.v47lift37.basic.annotation.processed.tsv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process GENCODE annotation files for both GRCh38 (hg38) and GRCh37 (hg19) assemblies\n",
    "\n",
    "for assembly in [\"hg38\", \"hg19\"]:\n",
    "    gtf_file = GTF_FILES[assembly]\n",
    "    output_file = OUTPUT_FILES[assembly]\n",
    "    \n",
    "    print(f\"Processing {assembly}: {gtf_file}\")\n",
    "    _ = process_gtf_file(gtf_file, output_file)\n",
    "    print(f\"Output saved to: {output_file}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb865d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Quality Control of CDS and Extract CDS Sequence\n",
    "\n",
    "This section extracts CDS sequences from the reference genome and validates them for downstream variant analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c02b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference genome: /data/for_paper/data/reference/hg38/hg38.fa\n",
      "Annotation file: /data/for_paper/data/reference/gencode.v47.basic.annotation.processed.tsv\n",
      "Output file: /data/for_paper/data/reference/gencode.v47.basic.annotation.processed.filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Additional Configuration for CDS Extraction\n",
    "# =============================================================================\n",
    "\n",
    "# Reference genome (GRCh38/hg38)\n",
    "REFERENCE_GENOME = f\"{REFERENCE_DIR}/hg38/hg38.fa\"\n",
    "\n",
    "# Input: Processed annotation from above\n",
    "ANNOTATION_FILE = OUTPUT_FILES[\"hg38\"]\n",
    "\n",
    "# Output: Filtered transcripts with CDS sequences\n",
    "FILTERED_TRANSCRIPTS_FILE = f\"{REFERENCE_DIR}/gencode.{GENCODE_VERSION}.basic.annotation.processed.filtered.tsv\"\n",
    "\n",
    "# Valid chromosomes for analysis\n",
    "VALID_CHROMS = [f'chr{i}' for i in range(1, 23)] + ['chrX']\n",
    "\n",
    "# DNA complement mapping for reverse complement operations\n",
    "COMPLEMENT = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'N': 'N'}\n",
    "\n",
    "print(f\"Reference genome: {REFERENCE_GENOME}\")\n",
    "print(f\"Annotation file: {ANNOTATION_FILE}\")\n",
    "print(f\"Output file: {FILTERED_TRANSCRIPTS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "486819ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CDS Extraction and Quality Control Functions\n",
    "# =============================================================================\n",
    "\n",
    "def extract_cds_sequence(row, fasta):\n",
    "    \"\"\"\n",
    "    Extract the coding sequence (CDS) for a transcript from the reference genome.\n",
    "    \n",
    "    This function:\n",
    "    1. Iterates through exons and extracts only the CDS-overlapping portions\n",
    "    2. Concatenates exon sequences in genomic order\n",
    "    3. Reverse complements for minus strand genes\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row containing transcript annotation (chrom, strand, cdsStart, cdsEnd, exonStarts, exonEnds)\n",
    "        fasta: Dictionary mapping chromosome names to their sequences\n",
    "        \n",
    "    Returns:\n",
    "        str: The complete CDS sequence in 5' to 3' orientation (transcript strand)\n",
    "    \"\"\"\n",
    "    chrom = row['chrom']\n",
    "    strand = row['strand']\n",
    "    cds_start = row['cdsStart']\n",
    "    cds_end = row['cdsEnd']\n",
    "    \n",
    "    # Parse comma-separated exon coordinates from annotation file\n",
    "    exon_starts = [int(x) for x in row['exonStarts'].rstrip(',').split(',')]\n",
    "    exon_ends = [int(x) for x in row['exonEnds'].rstrip(',').split(',')]\n",
    "\n",
    "    # Ensure exon boundaries encompass the full CDS (handles edge cases)\n",
    "    if exon_starts[0] > cds_start:\n",
    "        exon_starts[0] = cds_start\n",
    "    if exon_ends[-1] < cds_end:\n",
    "        exon_ends[-1] = cds_end\n",
    "\n",
    "    # Extract CDS sequence by iterating through exons\n",
    "    cds_sequence = \"\"\n",
    "    \n",
    "    for start, end in zip(exon_starts, exon_ends):\n",
    "        # Find overlap between this exon and the CDS region\n",
    "        overlap_start = max(start, cds_start)\n",
    "        overlap_end = min(end, cds_end)\n",
    "        \n",
    "        if overlap_start < overlap_end:\n",
    "            # Extract sequence from this exon segment (0-based coordinates)\n",
    "            seq = str(fasta[chrom][overlap_start:overlap_end]).upper()\n",
    "            cds_sequence += seq\n",
    "    \n",
    "    # For minus strand genes, reverse complement to get 5' to 3' orientation\n",
    "    if strand == '-':\n",
    "        cds_sequence = ''.join(COMPLEMENT[base] for base in cds_sequence[::-1])\n",
    "    \n",
    "    return cds_sequence\n",
    "\n",
    "\n",
    "def check_cds_quality(sequence):\n",
    "    \"\"\"\n",
    "    Validate CDS sequence quality for downstream variant analysis.\n",
    "    \n",
    "    Quality criteria checked:\n",
    "    1. Starts with ATG (methionine start codon)\n",
    "    2. Ends with a stop codon (TAA, TAG, or TGA)\n",
    "    3. Length is divisible by 3 (complete codons)\n",
    "    4. No premature stop codons within the coding region\n",
    "    \n",
    "    Args:\n",
    "        sequence: CDS nucleotide sequence string\n",
    "        \n",
    "    Returns:\n",
    "        dict: Quality metrics including boolean flags and sequence length\n",
    "    \"\"\"\n",
    "    if not sequence or len(sequence) < 3:\n",
    "        return {\n",
    "            'has_start_codon': False,\n",
    "            'has_stop_codon': False,\n",
    "            'length_divisible_by_3': False,\n",
    "            'has_internal_stop_codons': False,\n",
    "            'length': len(sequence) if sequence else 0\n",
    "        }\n",
    "    \n",
    "    # Check for canonical start codon (ATG = Methionine)\n",
    "    has_start_codon = sequence[:3] == 'ATG'\n",
    "    \n",
    "    # Check for stop codon at the end\n",
    "    has_stop_codon = sequence[-3:] in ['TAA', 'TAG', 'TGA']\n",
    "    \n",
    "    # CDS should be in-frame (length divisible by 3)\n",
    "    length_divisible_by_3 = len(sequence) % 3 == 0\n",
    "    \n",
    "    # Check for internal stop codons (premature termination)\n",
    "    # These indicate potential annotation errors or pseudogenes\n",
    "    has_internal_stop_codons = False\n",
    "    if len(sequence) >= 6:  # Need at least 2 codons to check for internal stops\n",
    "        # Check all codons except the last one (which should be a stop)\n",
    "        for i in range(0, len(sequence) - 3, 3):\n",
    "            codon = sequence[i:i+3]\n",
    "            if codon in ['TAA', 'TAG', 'TGA']:\n",
    "                has_internal_stop_codons = True\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        'has_start_codon': has_start_codon,\n",
    "        'has_stop_codon': has_stop_codon,\n",
    "        'length_divisible_by_3': length_divisible_by_3,\n",
    "        'has_internal_stop_codons': has_internal_stop_codons,\n",
    "        'length': len(sequence)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a083e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 chromosomes from /data/for_paper/data/reference/hg38/hg38.fa\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load Reference Genome (GRCh38/hg38)\n",
    "# =============================================================================\n",
    "# Pre-load chromosome sequences into memory for faster access during variant generation.\n",
    "# Only loading standard chromosomes (1-22, X, Y) - excluding patches and alternate contigs.\n",
    "\n",
    "import pyfaidx\n",
    "fasta = {}\n",
    "\n",
    "with pyfaidx.Fasta(REFERENCE_GENOME) as f:\n",
    "    for chrom in VALID_CHROMS:\n",
    "        fasta[chrom] = f[chrom][:].seq\n",
    "print(f\"Loaded {len(fasta)} chromosomes from {REFERENCE_GENOME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f350338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64,488 transcripts from /data/for_paper/data/reference/gencode.v47.basic.annotation.processed.tsv\n",
      "After deduplicating by genomic structure: 51,650 transcripts\n",
      "Extracting CDS sequences...\n",
      "Running quality checks...\n",
      "\n",
      "============================================================\n",
      "CDS Quality Summary (before filtering):\n",
      "============================================================\n",
      "Total transcripts: 51,650\n",
      "Has start codon (ATG): 51,419 (99.6%)\n",
      "Has stop codon (TAA/TAG/TGA): 51,341 (99.4%)\n",
      "Length divisible by 3: 51,573 (99.9%)\n",
      "Has internal stop codons: 113 (0.2%)\n",
      "All quality criteria met: 51,061\n",
      "\n",
      "After quality filtering: 51,061 transcripts\n",
      "After filtering to canonical transcripts: 19,407 transcripts\n",
      "After canonical filter + CDS deduplication: 19,310 unique transcripts\n",
      "  (Removed 31,751 transcripts)\n",
      "Saved 19,310 unique transcripts to /data/for_paper/data/reference/gencode.v47.basic.annotation.processed.filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load Annotations, Extract CDS Sequences, and Apply Quality Filters\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 1: Load processed GENCODE annotation\n",
    "# -----------------------------------------------------------------------------\n",
    "# Input: TSV file from the processing above containing\n",
    "# transcript coordinates, exon boundaries, and canonical status flags\n",
    "ann = pl.read_csv(ANNOTATION_FILE, separator='\\t')\n",
    "ann = ann.filter(pl.col('chrom').is_in(VALID_CHROMS))\n",
    "print(f\"Loaded {len(ann):,} transcripts from {ANNOTATION_FILE}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 2: Deduplicate transcripts with identical genomic structure\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multiple transcript IDs can map to the same CDS coordinates (e.g., RefSeq vs Ensembl)\n",
    "# Keep MANE Select > Ensembl Canonical when duplicates exist\n",
    "ann = ann.sort(['is_mane_select', 'is_canonical'], descending=True)\n",
    "ann = ann.unique(subset=['chrom', 'strand', 'cdsStart', 'cdsEnd', 'exonStarts', 'exonEnds'])\n",
    "print(f\"After deduplicating by genomic structure: {len(ann):,} transcripts\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 3: Extract CDS sequences from reference genome\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Extracting CDS sequences...\")\n",
    "sequences = [extract_cds_sequence(row, fasta) for row in ann.iter_rows(named=True)]\n",
    "ann = ann.with_columns(pl.Series(\"cds_sequence\", sequences))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 4: Quality control - validate CDS sequences\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Running quality checks...\")\n",
    "quality_checks = [check_cds_quality(row['cds_sequence']) for row in ann.iter_rows(named=True)]\n",
    "\n",
    "ann = ann.with_columns([\n",
    "    pl.Series(\"has_start_codon\", [q['has_start_codon'] for q in quality_checks]),\n",
    "    pl.Series(\"has_stop_codon\", [q['has_stop_codon'] for q in quality_checks]),\n",
    "    pl.Series(\"length_divisible_by_3\", [q['length_divisible_by_3'] for q in quality_checks]),\n",
    "    pl.Series(\"has_internal_stop_codons\", [q['has_internal_stop_codons'] for q in quality_checks]),\n",
    "    pl.Series(\"cds_length\", [q['length'] for q in quality_checks])\n",
    "])\n",
    "\n",
    "# Print quality summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CDS Quality Summary (before filtering):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total transcripts: {len(ann):,}\")\n",
    "print(f\"Has start codon (ATG): {ann['has_start_codon'].sum():,} ({ann['has_start_codon'].mean()*100:.1f}%)\")\n",
    "print(f\"Has stop codon (TAA/TAG/TGA): {ann['has_stop_codon'].sum():,} ({ann['has_stop_codon'].mean()*100:.1f}%)\")\n",
    "print(f\"Length divisible by 3: {ann['length_divisible_by_3'].sum():,} ({ann['length_divisible_by_3'].mean()*100:.1f}%)\")\n",
    "print(f\"Has internal stop codons: {ann['has_internal_stop_codons'].sum():,} ({ann['has_internal_stop_codons'].mean()*100:.1f}%)\")\n",
    "print(f\"All quality criteria met: {(ann['has_start_codon'] & ann['has_stop_codon'] & ann['length_divisible_by_3'] & ~ann['has_internal_stop_codons']).sum():,}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 5: Apply quality filters\n",
    "# -----------------------------------------------------------------------------\n",
    "# Keep only transcripts that pass all quality checks\n",
    "ann = ann.filter(\n",
    "    pl.col('has_start_codon') & \n",
    "    pl.col('has_stop_codon') & \n",
    "    pl.col('length_divisible_by_3') & \n",
    "    ~pl.col('has_internal_stop_codons')\n",
    ")\n",
    "print(f\"\\nAfter quality filtering: {len(ann):,} transcripts\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 6: Filter to canonical transcripts and deduplicate by CDS sequence\n",
    "# -----------------------------------------------------------------------------\n",
    "# Keep only MANE Select or Ensembl Canonical transcripts\n",
    "# Then deduplicate by CDS sequence (different transcripts can encode identical proteins)\n",
    "initial_count = len(ann)\n",
    "ann = ann.filter(pl.col('is_mane_select') | pl.col('is_canonical'))\n",
    "print(f\"After filtering to canonical transcripts: {len(ann):,} transcripts\")\n",
    "\n",
    "ann = ann.sort(['is_mane_select', 'is_canonical'], descending=True)\n",
    "ann = ann.unique(subset=['cds_sequence'], keep='first')\n",
    "ann = ann.sort(['chrom', 'txStart'])\n",
    "\n",
    "print(f\"After canonical filter + CDS deduplication: {len(ann):,} unique transcripts\")\n",
    "print(f\"  (Removed {initial_count - len(ann):,} transcripts)\")\n",
    "ann.write_csv(FILTERED_TRANSCRIPTS_FILE, separator='\\t')\n",
    "print(f\"Saved {len(ann):,} unique transcripts to {FILTERED_TRANSCRIPTS_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
