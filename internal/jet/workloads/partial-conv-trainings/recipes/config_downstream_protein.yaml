type: recipe
format_version: 1
maintainers: [dorotat]
loggers: [tensorboard, dllogger, extra]
labels:
  origin: bionemo
  workload_ref: ""
  bionemo_ci_pipeline_id: ""
  bionemo_commit_sha: ""
key_segments:
  domain: domain
  config_name: config
  warmup: warmup
  default_overwrites: False
  extra_overwrites: False
  seed: seed
  max_epochs: mepochs
launchers:
  type:slurm:
    ntasks_per_node: '{gpus}'
  name:dgxa100_dracooci:
    mounts:
      /workspace/bionemo/models: /lustre/fsw/portfolios/convai/projects/convai_bionemo_training/jet/models
      /workspace/bionemo/data: /lustre/fsw/portfolios/convai/projects/convai_bionemo_training/jet/data
spec:
  build: bionemo
  BIONEMO_HOME: "/workspace/bionemo"
  scope: ""
  platforms: [linux/amd64]
  wandb_project_name: ""
  pipeline_label: ""
  warmup: 200
  default_overwrites: "++exp_manager.create_tensorboard_logger=True ++exp_manager.wandb_logger_kwargs.offline=False ++exp_manager.create_wandb_logger=True ++exp_manager.create_checkpoint_callback=False ++exp_manager.resume_if_exists=False"
  extra_overwrites: ""
  script: |-    
    cd {BIONEMO_HOME};
    export WANDB_API_KEY=$BIONEMO_WANDB_API_KEY;
    model_tag={model}__{variant}__{config_name};
    python examples/{domain}/downstream/{variant}.py --config-path {BIONEMO_HOME}/examples/{domain}/{model}/conf --config-name {config_name} \
    trainer.num_nodes={nodes} trainer.devices={gpus} trainer.precision={precision} model.micro_batch_size={batch_size} \
    ++model.seed={seed} trainer.max_epochs={max_epochs} ++exp_manager.exp_dir={assets_dir} \
    {default_overwrites} {extra_overwrites}  \
    ++exp_manager.wandb_logger_kwargs.project={wandb_project_name} \
    ++exp_manager.wandb_logger_kwargs.group=${{model_tag}} \
    ++exp_manager.wandb_logger_kwargs.job_type={pipeline_label} \
    ++exp_manager.wandb_logger_kwargs.name=${{model_tag}}__{precision}prec_{batch_size}bs_{nodes}node_{gpus}gpu_{max_epochs}e \
    ++create_dllogger_callbacks=True ++create_trainer_metric_callback=True \
    ++dllogger_callbacks_kwargs.use_existing_dllogger=True ++dllogger_callbacks_kwargs.warmup={warmup} \
    ++dllogger_callbacks_kwargs.json_file={dllogger_file} ++trainer_metric_callback_kwargs.log_path={assets_dir} \
    ++logs_dir={logs_dir};
    if [ -z $SLURM_LOCALID ] || [ $SLURM_LOCALID = 0 ]
    then
      mkdir -p {tensorboard_dir}
      find {assets_dir} -type f -name "events.out.tfevents*" -exec cp {{}} {tensorboard_dir} \;
      latest_log="{assets_dir}/run_0/output_script-0.log";
      [ ! -f "$latest_log" ] && {{ echo "File $latest_log does not exist. Exiting with error."; exit 1; }};
      experiment_link=$(grep -o "View run at https://wandb.ai/[^']*" "$latest_log" | awk 'NR==1 {{print $4}}');
      project_link=$(grep -o "View project at https://wandb.ai/[^']*" "$latest_log" | awk 'NR==1 {{print $4}}');
      echo "{{WANDB_RUN_LINK: \"$experiment_link\", WANDB_PROJECT_LINK: \"$project_link\"}}" > {logs_dir}/extra.yaml
    fi
  time_limit: 14400
  artifacts: {}
metrics:
  throughput_train:
    goal: maximize
    tags: [ performance ]
    key: primary
  reduced_train_loss:
    goal: minimize
    tags: [accuracy]
    key: secondary
  val_loss:
    goal: minimize
    tags: [accuracy]
    key: tertiary
  val_3state_accuracy:
    goal: maximize
    tags: [accuracy]
    key: 4th
products:
  - domain: [protein]
    nodes: [ 1 ]
    gpus: [ 8 ]
    precision: [bf16-mixed]
    products:
      - variant: [downstream_flip]
        model: [esm2nv]
        config_name: [downstream_flip_sec_str]
        batch_size: [2]
        max_epochs: [20]
        seed: [1234]