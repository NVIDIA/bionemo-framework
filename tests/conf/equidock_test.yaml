do_training: False
do_testing: False
seed: 1204518

data:
  data_name: null
  num_workers: 0 # Should left 0 to avoid creating cuda content on a child thread
  pin_memory: True
  micro_batch_size: ${model.micro_batch_size}
  world_size: ${multiply:${trainer.devices}, ${trainer.num_nodes}}
  cache_path: ${oc.env:BIONEMO_HOME}/data/ # Folder from where to load/restore cached dataset
  data_dir: ${oc.env:BIONEMO_HOME}/data/
  graph_cutoff: 30.0
  graph_max_neighbor: 10
  split: 0
  pocket_cutoff: 8.0
  translation_interval: 5
  n_jobs: 0

model:
  name: EquiDock_${data.data_name}_inference
  seed: 42
  target: bionemo.model.protein.equidock.equidock_model.EquiDock
  restore_from_path: ${oc.env:BIONEMO_HOME}/models/protein/equidock/equidock_${data.data_name}.nemo # used when starting from a .nemo file
  micro_batch_size: 32
  resume_from_checkpoint: null
  debug: False
  iegmn_n_lays: 5
  graph_nodes: residues
  rot_model: kb_att
  noise_decay_rate: 0.0
  noise_initial: 0.0
  use_edge_features_in_gmn: True
  use_mean_node_features: True
  residue_emb_dim: 64
  iegmn_lay_hid_dim: 64
  input_edge_feats_dim: null
  dropout: 0.0
  nonlin: lkyrelu # ['lkyrelu', 'swish']
  cross_msgs: True
  layer_norm: LN # ['LN', 'BN', default]
  layer_norm_coors: '0'
  final_h_layer_norm: '0'
  use_dist_in_layers: True
  skip_weight_h: 0.5
  x_connection_init: 0.0
  leakyrelu_neg_slope: 0.01
  shared_layers: True
  num_att_heads: 50
  fine_tune: false
  pocket_ot_loss_weight: 1.0
  intersection_loss_weight: 10.0
  intersection_sigma: 25.0
  intersection_surface_ct: 10.0
  divide_coors_dist: false
  graph_residue_loc_is_alphaC: True # needed for preprocessing
  tensor_model_parallel_size: 1
  pipeline_model_parallel_size: 1

trainer:
  devices: 1
  num_nodes: 1
  precision: 32 # To activate AMP set to 16 or 'bf16'; otherwise will be float32
  accelerator: gpu # gpu or cpu
  max_epochs: 1000 # set to null when using max_steps instead with NeMo model
  max_steps: -1
  log_every_n_steps: 1 # number of iterations between logging
  val_check_interval: 1.0 # set to integer when using steps to determine frequency of validation, use fraction with epochs
  num_sanity_val_steps: 1.0 # set to 0 or small number to test validation before training
  limit_val_batches: 1.0 # number of batches in validation step, use fraction for fraction of data
  limit_test_batches: 1.0 # number of batches in test step, use fraction for fraction of data
  limit_train_batches: 1.0
  gradient_clip_val: 100.0
  logger: False # logger is provided by NeMo exp_manager
  enable_checkpointing: False # checkpointing is done by NeMo exp_manager
  reload_dataloaders_every_n_epochs: 10 # Set to a non-negative integer to reload dataloaders every n epochs. Default: ``0``.
  accumulate_grad_batches: 1
