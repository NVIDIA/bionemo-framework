{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92377fc2",
   "metadata": {},
   "source": [
    "## Parallel Head Data Preprocessing Example\n",
    "\n",
    "### Background and motivation\n",
    "In this notebook, we demonstrate how to preprocess data for training models with multiple prediction heads in parallel using the BioNemo Evo2 framework. This approach allows for efficient handling of diverse biological data types, such as RNA-seq and ChIP-seq, by leveraging parallel processing techniques.\n",
    "\n",
    "For this example, we will focus on preprocessing RNA-seq data from BigWig files and preparing it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace current config.py with modified version for parallel head support, saving a backup of the original.\n",
    "!cp /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py.bak\n",
    "!cp /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/config.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36dc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bionemo.core.utils.subprocess_utils import run_subprocess_safely  # noqa\n",
    "\n",
    "\n",
    "data_path = \"parallel_head_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d595929",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP: bool = True\n",
    "if CLEANUP and os.path.exists(data_path):\n",
    "    !rm -rf {data_path}\n",
    "    !rm -rf ./preprocessed_data\n",
    "    !rm parallel_preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11219043",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    !mkdir -p {data_path}\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/GCA_000525045.1_DREv1_genomic.fna -O {data_path}/GCA_000525045.1_DREv1_genomic.fna\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/SRR1145649_forward.normalized.bw -O {data_path}/SRR1145649_forward.normalized.bw\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/SRR1145649_reverse.normalized.bw -O {data_path}/SRR1145649_reverse.normalized.bw\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/GCA_000525045.1_DREv1_genomic.gtf -O {data_path}/GCA_000525045.1_DREv1_genomic.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a YAML config for preprocessing with RNA-Seq bigwig files.\n",
    "fasta_base = \"GCA_000525045.1_DREv1_genomic.fna\"\n",
    "bigwig_forward = \"SRR1145649_forward.normalized.bw\"  # No need for reverse, since both are handled together.\n",
    "full_fasta_path = os.path.abspath(os.path.join(data_path, fasta_base))\n",
    "output_prefix = \"fungi_dna_rnaseq\"\n",
    "\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: {output_prefix}\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "  fasta_rnaseq_bigwig_map:\n",
    "    {full_fasta_path}: {os.path.abspath(os.path.join(data_path, bigwig_forward))}\n",
    "\"\"\"\n",
    "with open(\"parallel_preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can run the preprocessing script with this config.\n",
    "!python \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads/preprocess.py \\\n",
    "    --config parallel_preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e852ff8",
   "metadata": {},
   "source": [
    "Now that we have a prepared dataset, we can proceed to train our model using the parallel head approach. This involves defining a model architecture that can handle multiple outputs and configuring the training process to optimize for each head simultaneously.\n",
    "\n",
    "We will use the simple dataset we created in the previous section to illustrate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets get a model to train\n",
    "if not os.path.exists(\"nemo2_evo2_1b_8k\"):\n",
    "    !evo2_convert_to_nemo2 \\\n",
    "      --model-path hf://arcinstitute/savanna_evo2_1b_base \\\n",
    "      --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the training dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\")) / output_prefix)\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_byte-level_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_byte-level_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_byte-level_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d39109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets copy folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Also copy over loss folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a90bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets go ahead and train a model with parallel heads!\n",
    "WARMUP_STEPS = 100\n",
    "MAX_STEPS = 1000\n",
    "VAL_CHECK_INTERVAL = 25\n",
    "\n",
    "MODEL_SUBNET_OPTION = \"--activation-checkpoint-recompute-num-layers 5\"\n",
    "\n",
    "!NCCL_P2P_DISABLE=1 NCCL_IB_DISABLE=1 python \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/run/train_parallel.py \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir ./preprocessed_data \\\n",
    "    --result-dir parallel_pretraining_demo \\\n",
    "    --experiment-name evo2 \\\n",
    "    --model-size 1b \\\n",
    "    --devices 2 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 8192 \\\n",
    "    --micro-batch-size 2 \\\n",
    "    --lr 0.000015 \\\n",
    "    --min-lr 0.0000149 \\\n",
    "    --warmup-steps {WARMUP_STEPS} \\\n",
    "    --grad-acc-batches 4 \\\n",
    "    --max-steps {MAX_STEPS} \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 5 \\\n",
    "    --wd 0.001 \\\n",
    "    --attention-dropout 0.01 \\\n",
    "    --hidden-dropout 0.01 \\\n",
    "    --val-check-interval {VAL_CHECK_INTERVAL} \\\n",
    "    {MODEL_SUBNET_OPTION} \\\n",
    "    --create-tensorboard-logger \\\n",
    "    --parallel-heads \\\n",
    "    --parallel-dna-head \\\n",
    "    --parallel-rna-seq-head \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP: bool = True\n",
    "if CLEANUP and os.path.exists(data_path):\n",
    "    !rm -rf {data_path}\n",
    "    !rm -rf parallel_pretraining_demo\n",
    "    !rm -rf preprocessed_data\n",
    "    !rm parallel_preprocess_config.yaml\n",
    "    !mv /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py.bak /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d34be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
