{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temporal Geneformer Inference and UMAP Visualization\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Run inference on the test dataset using a trained temporal geneformer checkpoint\n",
        "2. Extract cell embeddings from the model's latent space\n",
        "3. Generate UMAP projections to visualize the learned representations\n",
        "4. Create publication-quality visualizations of the latent space\n",
        "\n",
        "The temporal geneformer model learns to predict the next cell state in temporal trajectories, which should result in embeddings that capture meaningful biological progression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Paths and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint: /workspaces/bionemo-framework/sub-packages/bionemo-geneformer/examples/temporal_geneformer_results/temporal_geneformer/dev/checkpoints/epoch=0-val_loss=7.61-step=9999-consumed_samples=80000.0-last\n",
            "Data path: /workspaces/bionemo-framework/sub-packages/bionemo-geneformer/src/bionemo/geneformer/test_data/mar_por_datasets_splits/with_neighbors/test\n",
            "Results path: temporal_inference_results\n",
            "\n",
            "Checkpoint exists: True\n",
            "Data path exists: True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define paths\n",
        "checkpoint_path = Path(\"/workspaces/bionemo-framework/sub-packages/bionemo-geneformer/examples/temporal_geneformer_results/temporal_geneformer/dev/checkpoints/epoch=0-val_loss=7.61-step=9999-consumed_samples=80000.0-last\")\n",
        "data_path = Path(\"/workspaces/bionemo-framework/sub-packages/bionemo-geneformer/src/bionemo/geneformer/test_data/mar_por_datasets_splits/with_neighbors/test\")\n",
        "results_path = Path(\"./temporal_inference_results\")\n",
        "\n",
        "# Create results directory\n",
        "results_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configuration\n",
        "micro_batch_size = 64\n",
        "seq_length = 2048\n",
        "num_dataset_workers = 4\n",
        "num_gpus = 1\n",
        "\n",
        "print(f\"Checkpoint: {checkpoint_path}\")\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(f\"Results path: {results_path}\")\n",
        "print(f\"\\nCheckpoint exists: {checkpoint_path.exists()}\")\n",
        "print(f\"Data path exists: {data_path.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Inference\n",
        "\n",
        "We use the `infer_geneformer_scmap` command to run inference on the SCMAP test dataset. This version supports temporal training features with neighbor information.\n",
        "\n",
        "Key flags:\n",
        "- `--include-embeddings`: Extract cell-level embeddings (mean of all gene tokens, excluding special tokens) - enabled by default\n",
        "- `--include-hiddens`: Extract per-token hidden states (optional, for more detailed analysis)\n",
        "- `--include-input-ids`: Include input token IDs for mapping back to genes\n",
        "- `--next-cell-prediction`: Enable temporal mode (uses neighbor information)\n",
        "- `--filter-no-neighbors`: Only include cells that have neighbors in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda129.so')\n",
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "[NeMo W 2025-10-08 19:54:09 nemo_logging:405] Tokenizer vocab file: /home/ubuntu/.cache/bionemo/d8e3ea569bc43768c24aa651aff77722df202078415528497c22394046b08cc3-singlecell-scdltestdata-20241203.tar.gz.untar/cellxgene_2023-12-15_small_processed_scdl/train/geneformer.vocab already exists. Overwriting...\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_name_id_dict_gc30M.pkl?download=true\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Resource already exists, skipping download: https://huggingface.co/ctheodoris/Geneformer/resolve/main/geneformer/gene_dictionaries_30m/gene_median_dictionary_gc30M.pkl?download=true\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] No checksum provided, filename exists. Assuming it is complete.\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] *************** Preprocessing Finished ************\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All context parallel group ranks: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All model parallel group ranks: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has embedding group: [0]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] All embedding group ranks: [[0]]\n",
            "[NeMo I 2025-10-08 19:54:09 nemo_logging:393] Rank 0 has embedding rank: 0\n",
            "2025-10-08 19:54:09 - nemo.lightning.pytorch.strategies.megatron_strategy - INFO - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2025-10-08 19:54:10 - /workspaces/bionemo-framework/sub-packages/bionemo-llm/src/bionemo/llm/model/config.py - WARNING - Loading /workspaces/bionemo-framework/sub-packages/bionemo-geneformer/examples/temporal_geneformer_results/temporal_geneformer/dev/checkpoints/epoch=0-val_loss=7.61-step=9999-consumed_samples=80000.0-last\n",
            "[NeMo I 2025-10-08 19:54:10 nemo_logging:393] Padded vocab_size: 25472, original vocab_size: 25429, dummy tokens: 43.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "[NeMo W 2025-10-08 19:54:10 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
            "2025-10-08 19:54:10 - megatron.core.num_microbatches_calculator - INFO - setting number of microbatches to constant 1\n",
            "[NeMo I 2025-10-08 19:54:10 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 10300032\n",
            "2025-10-08 19:54:10 - megatron.core.distributed.distributed_data_parallel - INFO - Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False)\n",
            "2025-10-08 19:54:10 - megatron.core.distributed.param_and_grad_buffer - INFO - Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
            "Params for bucket 1 (10300032 elements, 10300032 padded size):\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc2.weight\n",
            "\tmodule.encoder.layers.2.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc1.weight\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc2.weight\n",
            "\tmodule.embedding.position_embeddings.weight\n",
            "\tmodule.encoder.layers.5.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.lm_head.dense.bias\n",
            "\tmodule.encoder.layers.4.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc1.weight\n",
            "\tmodule.encoder.layers.3.self_attention.linear_qkv.bias\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.2.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.encoder.layers.3.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.1.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.0.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.lm_head.dense.weight\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc2.weight\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc2.weight\n",
            "\tmodule.encoder.layers.3.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc1.weight\n",
            "\tmodule.encoder.layers.2.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.final_layernorm.bias\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.1.self_attention.linear_qkv.bias\n",
            "\tmodule.encoder.layers.5.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.final_layernorm.weight\n",
            "\tmodule.encoder.layers.4.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.encoder.layers.5.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.5.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.2.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.layers.1.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.2.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.lm_head.layer_norm.weight\n",
            "\tmodule.encoder.layers.4.self_attention.linear_qkv.bias\n",
            "\tmodule.encoder.layers.3.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.layers.0.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.5.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc1.weight\n",
            "\tmodule.encoder.layers.1.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.4.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.0.self_attention.linear_proj.weight\n",
            "\tmodule.encoder.layers.4.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.layers.1.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc2.weight\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc1.bias\n",
            "\tmodule.encoder.layers.0.self_attention.linear_qkv.bias\n",
            "\tmodule.output_layer.bias\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
            "\tmodule.encoder.layers.1.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.layers.4.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc2.weight\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.5.mlp.linear_fc2.bias\n",
            "\tmodule.encoder.layers.2.self_attention.linear_qkv.bias\n",
            "\tmodule.encoder.layers.1.self_attention.linear_qkv.layer_norm_weight\n",
            "\tmodule.embedding.word_embeddings.weight\n",
            "\tmodule.encoder.layers.5.self_attention.linear_qkv.bias\n",
            "\tmodule.encoder.layers.3.mlp.linear_fc1.weight\n",
            "\tmodule.encoder.layers.0.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.lm_head.layer_norm.bias\n",
            "\tmodule.encoder.layers.4.self_attention.linear_qkv.weight\n",
            "\tmodule.encoder.layers.2.mlp.linear_fc1.layer_norm_bias\n",
            "\tmodule.encoder.layers.0.self_attention.linear_proj.bias\n",
            "\tmodule.encoder.layers.3.self_attention.linear_qkv.layer_norm_bias\n",
            "\tmodule.encoder.layers.0.mlp.linear_fc1.weight\n",
            "2025-10-08 19:54:10 - megatron.core.optimizer - INFO - Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.float32, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
            "2025-10-08 19:54:11 - root - INFO - Instantiating MegatronPretrainingSampler with total_samples: 121698 and consumed_samples: 0\n",
            "2025-10-08 20:03:33 - root - INFO - Inference predictions are stored in temporal_inference_results/predictions__rank_0.pt\n",
            "dict_keys(['token_logits', 'binary_logits', 'input_ids', 'embeddings'])\n"
          ]
        }
      ],
      "source": [
        "!infer_geneformer_scmap \\\n",
        "    --data-dir {data_path} \\\n",
        "    --checkpoint-path {checkpoint_path} \\\n",
        "    --results-path {results_path} \\\n",
        "    --micro-batch-size {micro_batch_size} \\\n",
        "    --seq-length {seq_length} \\\n",
        "    --num-dataset-workers {num_dataset_workers} \\\n",
        "    --num-gpus {num_gpus} \\\n",
        "    --include-input-ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!infer_geneformer_scmap \\\n",
        "    --data-dir {data_path} \\\n",
        "    --checkpoint-path {checkpoint_path} \\\n",
        "    --results-path {results_path} \\\n",
        "    --micro-batch-size {micro_batch_size} \\\n",
        "    --seq-length {seq_length} \\\n",
        "    --num-dataset-workers {num_dataset_workers} \\\n",
        "    --num-gpus {num_gpus} \\\n",
        "    --include-input-ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Inference Results\n",
        "\n",
        "The inference results are saved as a PyTorch `.pt` file containing:\n",
        "- `embeddings`: Cell-level representations (N_cells x embedding_dim)\n",
        "- `hidden_states`: Per-token hidden states (N_cells x seq_len x embedding_dim)\n",
        "- `input_ids`: Token IDs for each cell\n",
        "- `token_logits`: Output logits (if included)\n",
        "- `binary_logits`: Binary classification logits (if applicable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading predictions from: temporal_inference_results/predictions__rank_0.pt\n",
            "\n",
            "Available keys: dict_keys(['token_logits', 'binary_logits', 'input_ids', 'embeddings'])\n",
            "\n",
            "Embeddings shape: (121698, 256)\n",
            "Number of cells: 121698\n",
            "Embedding dimension: 256\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load predictions\n",
        "predictions_file = results_path / \"predictions__rank_0.pt\"\n",
        "print(f\"Loading predictions from: {predictions_file}\")\n",
        "\n",
        "predictions = torch.load(predictions_file, weights_only=False)\n",
        "\n",
        "# Check what keys are available\n",
        "print(f\"\\nAvailable keys: {predictions.keys()}\")\n",
        "\n",
        "# Extract embeddings\n",
        "embeddings = predictions[\"embeddings\"].float().cpu().numpy()\n",
        "print(f\"\\nEmbeddings shape: {embeddings.shape}\")\n",
        "print(f\"Number of cells: {embeddings.shape[0]}\")\n",
        "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Metadata and Dataset Labels\n",
        "\n",
        "We'll load metadata to understand which dataset each cell belongs to. This is useful for visualizing how well the model integrates different datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 parquet files\n",
            "Loaded dataframe_0.parquet: 21192 rows\n",
            "Loaded dataframe_1.parquet: 21633 rows\n",
            "Loaded dataframe_2.parquet: 18323 rows\n",
            "\n",
            "Total metadata rows: 61148\n",
            "\n",
            "Metadata columns: ['soma_joinid', 'feature_id', 'feature_name', 'feature_length', 'nnz', 'n_measured_obs', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm']\n",
            "\n",
            "First few rows:\n",
            "   soma_joinid       feature_id feature_name  feature_length      nnz  \\\n",
            "0            1  ENSG00000121410         A1BG            3999  5640476   \n",
            "1            2  ENSG00000268895     A1BG-AS1            3374  3071864   \n",
            "2            4  ENSG00000175899          A2M            6318  7894261   \n",
            "3            5  ENSG00000245105      A2M-AS1            2948  1637794   \n",
            "4            8  ENSG00000184389      A3GALT2            1023   439067   \n",
            "\n",
            "   n_measured_obs  n_cells     mt  n_cells_by_counts  mean_counts  \\\n",
            "0        62641311    15746  False              15746     0.189815   \n",
            "1        61946057     2108  False               2108     0.020749   \n",
            "2        62704378      216  False                216     0.002144   \n",
            "3        62086816     1767  False               1767     0.017775   \n",
            "4        53780311        3  False                  3     0.000029   \n",
            "\n",
            "   pct_dropout_by_counts  total_counts  highly_variable     means  \\\n",
            "0              84.992804       19916.0            False  0.483928   \n",
            "1              97.990908        2177.0            False  0.060711   \n",
            "2              99.794135         225.0            False  0.006057   \n",
            "3              98.315908        1865.0             True  0.059115   \n",
            "4              99.997141           3.0             True  0.000119   \n",
            "\n",
            "   dispersions  dispersions_norm  \n",
            "0     3.112418          0.541391  \n",
            "1     3.347481         -0.935603  \n",
            "2     3.516537          0.555501  \n",
            "3     3.680163          4.099755  \n",
            "4     4.111606          2.080875  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Load feature metadata (contains dataset labels and other info)\n",
        "features_dir = data_path / \"features\"\n",
        "\n",
        "# Read all parquet files and combine them\n",
        "parquet_files = sorted(features_dir.glob(\"dataframe_*.parquet\"))\n",
        "print(f\"Found {len(parquet_files)} parquet files\")\n",
        "\n",
        "# Load and concatenate all dataframes\n",
        "dfs = []\n",
        "for pf in parquet_files:\n",
        "    df = pd.read_parquet(pf)\n",
        "    dfs.append(df)\n",
        "    print(f\"Loaded {pf.name}: {len(df)} rows\")\n",
        "\n",
        "metadata = pd.concat(dfs, ignore_index=True)\n",
        "print(f\"\\nTotal metadata rows: {len(metadata)}\")\n",
        "print(f\"\\nMetadata columns: {metadata.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(metadata.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No dataset column found. Available columns:\n",
            "['soma_joinid', 'feature_id', 'feature_name', 'feature_length', 'nnz', 'n_measured_obs', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm']\n",
            "\n",
            "Created dummy dataset labels for visualization purposes\n",
            "\n",
            "Embeddings shape: 121698\n",
            "Labels length: 61148\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Mismatch between embeddings and labels!",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEmbeddings shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabels length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset_labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_labels) == embeddings.shape[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mMismatch between embeddings and labels!\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: Mismatch between embeddings and labels!"
          ]
        }
      ],
      "source": [
        "# Extract dataset labels if available\n",
        "if 'dataset' in metadata.columns:\n",
        "    dataset_labels = metadata['dataset'].values\n",
        "    print(f\"Dataset distribution:\")\n",
        "    print(metadata['dataset'].value_counts())\n",
        "elif 'dataset_index' in metadata.columns:\n",
        "    dataset_labels = metadata['dataset_index'].values\n",
        "    print(f\"Dataset distribution:\")\n",
        "    print(metadata['dataset_index'].value_counts())\n",
        "else:\n",
        "    # If no dataset column, create dummy labels based on filename patterns\n",
        "    print(\"No dataset column found. Available columns:\")\n",
        "    print(metadata.columns.tolist())\n",
        "    # Create dummy labels (split in half for visualization)\n",
        "    n_cells = len(metadata)\n",
        "    dataset_labels = np.array([\"Dataset A\"] * (n_cells // 2) + [\"Dataset B\"] * (n_cells - n_cells // 2))\n",
        "    print(\"\\nCreated dummy dataset labels for visualization purposes\")\n",
        "\n",
        "# Ensure embeddings and labels have same length\n",
        "print(f\"\\nEmbeddings shape: {embeddings.shape[0]}\")\n",
        "print(f\"Labels length: {len(dataset_labels)}\")\n",
        "assert len(dataset_labels) == embeddings.shape[0], \"Mismatch between embeddings and labels!\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate UMAP Projection\n",
        "\n",
        "UMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique that preserves both local and global structure. It's particularly effective for visualizing high-dimensional embeddings.\n",
        "\n",
        "Key parameters:\n",
        "- `n_neighbors`: Controls balance between local and global structure (15-50 typical)\n",
        "- `min_dist`: Controls cluster tightness (0.0-0.5 typical)\n",
        "- `metric`: Distance metric ('cosine' works well for embeddings)\n",
        "- `n_components`: Number of dimensions to reduce to (2 for visualization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import umap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize embeddings (optional but often helpful)\n",
        "scaler = StandardScaler()\n",
        "embeddings_scaled = scaler.fit_transform(embeddings)\n",
        "\n",
        "print(\"Computing UMAP projection...\")\n",
        "print(\"This may take a few minutes for large datasets...\")\n",
        "\n",
        "# Create UMAP reducer\n",
        "reducer = umap.UMAP(\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.1,\n",
        "    n_components=2,\n",
        "    metric='cosine',\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Fit and transform\n",
        "umap_embedding = reducer.fit_transform(embeddings_scaled)\n",
        "\n",
        "print(f\"\\nUMAP embedding shape: {umap_embedding.shape}\")\n",
        "print(f\"UMAP1 range: [{umap_embedding[:, 0].min():.2f}, {umap_embedding[:, 0].max():.2f}]\")\n",
        "print(f\"UMAP2 range: [{umap_embedding[:, 1].min():.2f}, {umap_embedding[:, 1].max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save UMAP Coordinates\n",
        "\n",
        "Save the UMAP coordinates so you don't have to recompute them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save UMAP coordinates\n",
        "np.save(results_path / \"umap_coordinates.npy\", umap_embedding)\n",
        "print(f\"UMAP coordinates saved to {results_path / 'umap_coordinates.npy'}\")\n",
        "\n",
        "# Save metadata with UMAP coordinates\n",
        "metadata_with_umap = metadata.copy()\n",
        "metadata_with_umap['UMAP1'] = umap_embedding[:, 0]\n",
        "metadata_with_umap['UMAP2'] = umap_embedding[:, 1]\n",
        "metadata_with_umap['dataset_label'] = dataset_labels\n",
        "metadata_with_umap.to_csv(results_path / \"metadata_with_umap.csv\", index=False)\n",
        "print(f\"Metadata with UMAP saved to {results_path / 'metadata_with_umap.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize UMAP Projection\n",
        "\n",
        "Create a publication-quality UMAP visualization showing how the temporal geneformer model integrates different datasets in the latent space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"notebook\", font_scale=1.2)\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
        "\n",
        "# Get unique labels and assign colors\n",
        "unique_labels = np.unique(dataset_labels)\n",
        "print(f\"Unique labels: {unique_labels}\")\n",
        "\n",
        "# Use tab10 colormap for distinct colors\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
        "\n",
        "# Plot each dataset separately\n",
        "for i, label in enumerate(unique_labels):\n",
        "    mask = dataset_labels == label\n",
        "    ax.scatter(\n",
        "        umap_embedding[mask, 0],\n",
        "        umap_embedding[mask, 1],\n",
        "        c=[colors[i]],\n",
        "        label=f\"{label}\",\n",
        "        alpha=0.6,\n",
        "        s=5,\n",
        "        rasterized=True  # Better performance for many points\n",
        "    )\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('UMAP1', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('UMAP2', fontsize=14, fontweight='bold')\n",
        "ax.set_title('Temporal Geneformer - Latent Space Integration', fontsize=16, fontweight='bold')\n",
        "ax.legend(title=\"Dataset\", loc='best', frameon=True, fancybox=True, framealpha=0.9, fontsize=12)\n",
        "\n",
        "# Add annotation\n",
        "ax.text(0.5, 1.02, \"UMAP projection with each dataset highlighted\",\n",
        "        ha='center', va='bottom', transform=ax.transAxes, fontsize=11, style='italic')\n",
        "\n",
        "# Remove top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "output_file = results_path / \"temporal_geneformer_umap.png\"\n",
        "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
        "print(f\"\\nFigure saved to {output_file}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
