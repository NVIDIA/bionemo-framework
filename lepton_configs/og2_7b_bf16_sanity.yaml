# OpenGenome2 Metagenome 7B - BF16 Sanity Check (FP32 master weights, NO FP8)
# 6 nodes H100, THD format with sequence packing, GQA enabled
# Purpose: Baseline to verify FP32 master weights + BF16 converges well
# GBS = 1 * 8 * 6 * 8 = 384
defaults:
  - _self_

job_name: "og2-7b-bf16-sanity"
node_group: "yo-bom-lepton-001"
resource_shape: "gpu.8xh100-sxm"

# 6 nodes - GBS = 1 * 8 * 6 * 8 = 384
num_nodes: 6
gpus_per_node: 8
num_train_steps: 182314
micro_batch_size: 1
grad_acc_steps: 8

# HuggingFace streaming dataset
dataset_path: ""
data_dir: ""
num_workers: 1

# Code and paths
code_path: "/data/savithas/bionemo-framework/bionemo-recipes/recipes/llama3_native_te"
train_script: "train_fsdp2.py"
hydra_config: "L2_og2_metagenome_7b_thd_gqa_bf16_sanity"

# Validation DISABLED
validation_enabled: false

# Matching other THD GQA runs
spike_no_more_embedding_init: true
skip_embedding_weight_decay: false
use_megatron_scaled_init: true
use_weight_decay_grouping: true

# Disable meta device init
use_meta_device: false

# FP8 DISABLED - pure BF16
fp8_enabled: false

# FP32 Master Weights enabled
use_fp32_master_weights: true

# Log every step
logger_frequency: 1

# Checkpointing - save every 10k steps, async enabled
checkpoint_dir: "/data/savithas/checkpoints/og2-7b-bf16-sanity"  # pragma: allowlist secret
save_every_n_steps: 10000
async_save: true

# WandB configuration
wandb_project: "llama3-metagenome-7b"
wandb_name: "og2-7b-bf16-sanity"
wandb_secret: "wandb.savithas"  # pragma: allowlist secret

# HuggingFace token
hf_secret: "HUGGING_FACE_HUB_TOKEN.savithas"  # pragma: allowlist secret

# Nodes to exclude (ECC errors / NVLink issues)
exclude_nodes:
  - node-ip-10-50-80-195
  - node-ip-10-50-81-231
  - nvidia-lepton093
  - nvidia-lepton007

# Container configuration
container:
  image: "nvcr.io/nvidia/pytorch:25.11-py3"
  registry_auth: "lepton-nvidia-cvai-bnmo-trng"
