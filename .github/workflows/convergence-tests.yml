name: "BioNeMo Model Convergence Tests"

on:
  workflow_dispatch:
    inputs:
      gpu_type:
        description: "GPU type to use"
        required: true
        default: "h100-sxm"
        type: choice
        options:
          - h100-sxm
          - h200
      model_config:
        description: "Model configuration to use"
        required: true
        default: "esm2_accelerate"
        type: choice
        options:
          - esm2_accelerate_te.yaml
          - esm2_native_te
          - geneformer_native_te_mfsdp_fp8
      config_override:
        description: "Optional: run only these product configs (CSV). Examples: 10m  or  10m,4b. Leave blank to run all."
        required: false
        type: string
      branch:
        description: "Branch to use (ignored if commit SHA is provided)"
        required: true
        default: "main"
        type: string
      commit_sha:
        description: "Commit SHA (optional - overrides branch if provided)"
        required: false
        type: string

jobs:
  submit-lepton-jobs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            ci/lepton/model_convergence/requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ci/lepton/model_convergence/requirements.txt

      - name: Submit Lepton Jobs
        env:
          LEP_LOGIN_CREDENTIALS: ${{ secrets.LEP_LOGIN_CREDENTIALS }}
        run: |
          set -euo pipefail
          lep login -c "$LEP_LOGIN_CREDENTIALS" || true

          # Map GPU type to node group
          if [ "${{ inputs.gpu_type }}" = "h200" ]; then
            NODE_GROUP="nv-int-multiteam-nebius-h200-01"
          elif [ "${{ inputs.gpu_type }}" = "h100-sxm" ]; then
            NODE_GROUP="yo-bom-lepton-001"
          else
            echo "Error: Unknown GPU type: ${{ inputs.gpu_type }}"
            exit 1
          fi

          RUN_ONLY_ARGS=""
          if [ -n "${{ inputs.config_override }}" ]; then
            # Users can type: 10m  or  10m,4b
            RUN_ONLY_ARGS="+run_only=${{ inputs.config_override }}"
          fi

          python ci/lepton/model_convergence/scripts/launch_job.py \
            --config-name recipes/${{ inputs.model_config }} \
            $RUN_ONLY_ARGS \
            branch=${{ inputs.branch }} \
            commit_sha=${{ inputs.commit_sha }} \
            node_group=$NODE_GROUP \
            gpu_type=${{ inputs.gpu_type }}
